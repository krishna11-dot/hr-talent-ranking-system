{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeTp0BseF+NXW3n3hNRVnT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna11-dot/hr-talent-ranking-system/blob/main/HR_Candidate_Ranking__.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0mAO3BsiQXvx",
        "outputId": "481da51e-97c9-4fa5-aa93-b4693ce6bc4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ba218d26-a3c6-4bb4-b865-f06eeaf465c9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ba218d26-a3c6-4bb4-b865-f06eeaf465c9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving potential-talents.xlsx to potential-talents (3).xlsx\n",
            "\n",
            "Loading data from potential-talents (3).xlsx...\n",
            "\n",
            "==================================================\n",
            " TALENT ANALYSIS \n",
            "==================================================\n",
            "\n",
            " ANALYSIS OVERVIEW\n",
            "------------------------------\n",
            "Total Candidates Analyzed: 104\n",
            "Unique Job Titles: 26\n",
            "HR-Related Roles: 104\n",
            "\n",
            " SCORE DISTRIBUTION\n",
            "------------------------------\n",
            "Mean Score:     0.465\n",
            "Median Score:   0.507\n",
            "Score Range:    0.062 - 0.858\n",
            "\n",
            "Score Quartiles:\n",
            "25th Percentile: 0.186\n",
            "50th Percentile: 0.507\n",
            "75th Percentile: 0.693\n",
            "\n",
            " TOP CANDIDATES ANALYSIS\n",
            "------------------------------\n",
            "\n",
            " INITIAL RANKINGS\n",
            "--------------------------------------------------\n",
            "Ranking Criteria:\n",
            "• Job titles standardized\n",
            "• Locations normalized\n",
            "• Network scores weighted\n",
            "\n",
            "TOP CANDIDATES LISTING:\n",
            "--------------------------------------------------\n",
            "\n",
            "1. [Rank 1]\n",
            "Original Title: Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis\n",
            "Processed Title: seeking entry hr manager\n",
            "Original Location: Cape Girardeau, Missouri\n",
            "Processed Location: cape girardeau, missouri\n",
            "Network: 0.9\n",
            "Score: 0.858\n",
            "\n",
            "2. [Rank 2]\n",
            "Original Title: Seeking Human Resources HRIS and Generalist Positions\n",
            "Processed Title: seeking hr generalist hris\n",
            "Original Location: Greater Philadelphia Area\n",
            "Processed Location: philadelphia\n",
            "Network: 1.0\n",
            "Score: 0.802\n",
            "\n",
            "3. [Rank 3]\n",
            "Original Title: Seeking Human Resources HRIS and Generalist Positions\n",
            "Processed Title: seeking hr generalist hris\n",
            "Original Location: Greater Philadelphia Area\n",
            "Processed Location: philadelphia\n",
            "Network: 1.0\n",
            "Score: 0.802\n",
            "\n",
            "4. [Rank 4]\n",
            "Original Title: Seeking Human Resources HRIS and Generalist Positions\n",
            "Processed Title: seeking hr generalist hris\n",
            "Original Location: Greater Philadelphia Area\n",
            "Processed Location: philadelphia\n",
            "Network: 1.0\n",
            "Score: 0.801\n",
            "\n",
            "5. [Rank 5]\n",
            "Original Title: Seeking Human Resources HRIS and Generalist Positions\n",
            "Processed Title: seeking hr generalist hris\n",
            "Original Location: Greater Philadelphia Area\n",
            "Processed Location: philadelphia\n",
            "Network: 1.0\n",
            "Score: 0.800\n",
            "\n",
            "6. [Rank 6]\n",
            "Original Title: Aspiring Human Resources Manager, seeking internship in Human Resources.\n",
            "Processed Title: seeking hr manager\n",
            "Original Location: Houston, Texas Area\n",
            "Processed Location: texas\n",
            "Network: 0.8\n",
            "Score: 0.773\n",
            "\n",
            "7. [Rank 7]\n",
            "Original Title: Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.\n",
            "Processed Title: seeking hr manager\n",
            "Original Location: Virginia Beach, Virginia\n",
            "Processed Location: virginia beach, virginia\n",
            "Network: 0.9\n",
            "Score: 0.764\n",
            "\n",
            "8. [Rank 8]\n",
            "Original Title: HR Manager at Endemol Shine North America\n",
            "Processed Title: hr manager\n",
            "Original Location: Los Angeles, California\n",
            "Processed Location: california\n",
            "Network: 1.0\n",
            "Score: 0.743\n",
            "\n",
            "9. [Rank 9]\n",
            "Original Title: Business Management Major and Aspiring Human Resources Manager\n",
            "Processed Title: aspiring hr manager\n",
            "Original Location: Monroe, Louisiana Area\n",
            "Processed Location: monroe, louisiana\n",
            "Network: 0.8\n",
            "Score: 0.742\n",
            "\n",
            "10. [Rank 10]\n",
            "Original Title: Aspiring Human Resources Specialist\n",
            "Processed Title: aspiring hr specialist\n",
            "Original Location: Greater New York City Area\n",
            "Processed Location: new york\n",
            "Network: 0.8\n",
            "Score: 0.727\n",
            "\n",
            " ROLE RECOMMENDATIONS\n",
            "------------------------------\n",
            "\n",
            "Cutoff Analysis:\n",
            "\n",
            "High-potential HR candidates - Direct fit:\n",
            "• Score threshold: 0.8\n",
            "• Candidates: 5 (4.8%)\n",
            "\n",
            "Strong HR support/specialist potential:\n",
            "• Score threshold: 0.6\n",
            "• Candidates: 32 (30.8%)\n",
            "\n",
            "Consider for HR administrative roles:\n",
            "• Score threshold: 0.4\n",
            "• Candidates: 69 (66.3%)\n",
            "\n",
            "Recommend alternative career paths:\n",
            "• Score threshold: 0.2\n",
            "• Candidates: 72 (69.2%)\n",
            "\n",
            " LOCATION INSIGHTS\n",
            "------------------------------\n",
            "\n",
            "Top 5 Locations (Original → Processed):\n",
            "• Kanada → canada: 12 candidates\n",
            "• Houston, Texas Area → texas: 8 candidates\n",
            "• Raleigh-Durham, North Carolina Area → north carolina: 8 candidates\n",
            "• Greater New York City Area → new york: 7 candidates\n",
            "• Houston, Texas → texas: 7 candidates\n",
            "\n",
            "==================================================\n",
            "End of Analysis Report\n",
            "==================================================\n",
            "\n",
            "Starring candidate 6...\n",
            "\n",
            "==================================================\n",
            " TALENT ANALYSIS \n",
            "==================================================\n",
            "\n",
            " ANALYSIS OVERVIEW\n",
            "------------------------------\n",
            "Total Candidates Analyzed: 104\n",
            "Unique Job Titles: 26\n",
            "HR-Related Roles: 104\n",
            "\n",
            " SCORE DISTRIBUTION\n",
            "------------------------------\n",
            "Mean Score:     0.541\n",
            "Median Score:   0.534\n",
            "Score Range:    0.065 - 1.168\n",
            "\n",
            "Score Quartiles:\n",
            "25th Percentile: 0.223\n",
            "50th Percentile: 0.534\n",
            "75th Percentile: 0.747\n",
            "\n",
            " TOP CANDIDATES ANALYSIS\n",
            "------------------------------\n",
            "\n",
            " RANKING CHANGES AFTER STARRING\n",
            "--------------------------------------------------\n",
            "\n",
            " STARRING IMPACT ANALYSIS\n",
            "------------------------------\n",
            "\n",
            "Starred Candidate:\n",
            "Title: Student at Humber College and Aspiring Human Resources Generalist\n",
            "Location: Kanada → canada\n",
            "Score: 0.859 → 1.168\n",
            "\n",
            " EFFECTIVENESS METRICS\n",
            "------------------------------\n",
            "Score Improvements:\n",
            "• High potential (>0.8): 3 → 18 candidates\n",
            "• Strong potential (>0.6): 32 → 40 candidates\n",
            "• Similar profiles boosted: 18\n",
            "\n",
            "Fairness Validation:\n",
            "• Geographic Distribution: 26 regions\n",
            "• Network Impact: Minimal (correlation: -0.035)\n",
            "\n",
            "TOP CANDIDATES LISTING:\n",
            "--------------------------------------------------\n",
            "\n",
            "1. [Rank 1]\n",
            "Original Title: Student at Humber College and Aspiring Human Resources Generalist\n",
            "Processed Title: aspiring hr generalist undergraduate\n",
            "Original Location: Kanada\n",
            "Processed Location: canada\n",
            "Network: 0.9\n",
            "Score: 1.168\n",
            "\n",
            "2. [Rank 2]\n",
            "Original Title: Seeking Human Resources HRIS and Generalist Positions\n",
            "Processed Title: seeking hr generalist hris\n",
            "Original Location: Greater Philadelphia Area\n",
            "Processed Location: philadelphia\n",
            "Network: 1.0\n",
            "Score: 1.034\n",
            "\n",
            "3. [Rank 3]\n",
            "Original Title: Seeking Human Resources HRIS and Generalist Positions\n",
            "Processed Title: seeking hr generalist hris\n",
            "Original Location: Greater Philadelphia Area\n",
            "Processed Location: philadelphia\n",
            "Network: 1.0\n",
            "Score: 1.034\n",
            "\n",
            "4. [Rank 4]\n",
            "Original Title: Seeking Human Resources HRIS and Generalist Positions\n",
            "Processed Title: seeking hr generalist hris\n",
            "Original Location: Greater Philadelphia Area\n",
            "Processed Location: philadelphia\n",
            "Network: 1.0\n",
            "Score: 1.032\n",
            "\n",
            "5. [Rank 5]\n",
            "Original Title: Seeking Human Resources HRIS and Generalist Positions\n",
            "Processed Title: seeking hr generalist hris\n",
            "Original Location: Greater Philadelphia Area\n",
            "Processed Location: philadelphia\n",
            "Network: 1.0\n",
            "Score: 1.032\n",
            "\n",
            "6. [Rank 6]\n",
            "Original Title: Student at Humber College and Aspiring Human Resources Generalist\n",
            "Processed Title: aspiring hr generalist undergraduate\n",
            "Original Location: Kanada\n",
            "Processed Location: canada\n",
            "Network: 0.9\n",
            "Score: 0.973\n",
            "\n",
            "7. [Rank 7]\n",
            "Original Title: Human Resources Generalist at ScottMadden, Inc.\n",
            "Processed Title: hr generalist\n",
            "Original Location: Raleigh-Durham, North Carolina Area\n",
            "Processed Location: north carolina\n",
            "Network: 1.0\n",
            "Score: 0.972\n",
            "\n",
            "8. [Rank 8]\n",
            "Original Title: Student at Humber College and Aspiring Human Resources Generalist\n",
            "Processed Title: aspiring hr generalist undergraduate\n",
            "Original Location: Kanada\n",
            "Processed Location: canada\n",
            "Network: 0.9\n",
            "Score: 0.971\n",
            "\n",
            "9. [Rank 9]\n",
            "Original Title: Human Resources Generalist at Loparex\n",
            "Processed Title: hr generalist\n",
            "Original Location: Raleigh-Durham, North Carolina Area\n",
            "Processed Location: north carolina\n",
            "Network: 1.0\n",
            "Score: 0.971\n",
            "\n",
            "10. [Rank 10]\n",
            "Original Title: Student at Humber College and Aspiring Human Resources Generalist\n",
            "Processed Title: aspiring hr generalist undergraduate\n",
            "Original Location: Kanada\n",
            "Processed Location: canada\n",
            "Network: 0.9\n",
            "Score: 0.971\n",
            "\n",
            " ROLE RECOMMENDATIONS\n",
            "------------------------------\n",
            "\n",
            "Cutoff Analysis:\n",
            "\n",
            "High-potential HR candidates - Direct fit:\n",
            "• Score threshold: 0.8\n",
            "• Candidates: 18 (17.3%)\n",
            "\n",
            "Strong HR support/specialist potential:\n",
            "• Score threshold: 0.6\n",
            "• Candidates: 40 (38.5%)\n",
            "\n",
            "Consider for HR administrative roles:\n",
            "• Score threshold: 0.4\n",
            "• Candidates: 70 (67.3%)\n",
            "\n",
            "Recommend alternative career paths:\n",
            "• Score threshold: 0.2\n",
            "• Candidates: 82 (78.8%)\n",
            "\n",
            " LOCATION INSIGHTS\n",
            "------------------------------\n",
            "\n",
            "Top 5 Locations (Original → Processed):\n",
            "• Kanada → canada: 12 candidates\n",
            "• Houston, Texas Area → texas: 8 candidates\n",
            "• Raleigh-Durham, North Carolina Area → north carolina: 8 candidates\n",
            "• Greater New York City Area → new york: 7 candidates\n",
            "• Houston, Texas → texas: 7 candidates\n",
            "\n",
            "==================================================\n",
            "End of Analysis Report\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Core data manipulation libraries\n",
        "import pandas as pd         # Pandas for structured data handling and analysis\n",
        "import numpy as np         # NumPy for numerical operations and array handling\n",
        "\n",
        "# Natural Language Processing (NLP) libraries\n",
        "import nltk               # Natural Language Toolkit - core NLP functionality\n",
        "from nltk.tokenize import word_tokenize  # Splits text into individual words/tokens\n",
        "from nltk.corpus import stopwords        # Common words to filter out (e.g., 'the', 'is', 'at')\n",
        "from nltk.stem import WordNetLemmatizer  # Reduces words to their base/dictionary form\n",
        "\n",
        "# Machine Learning and Text Processing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Converts text to numerical features\n",
        "from sklearn.metrics.pairwise import cosine_similarity      # Measures similarity between texts\n",
        "from sklearn.cluster import KMeans                         # Clustering algorithm\n",
        "from sklearn.preprocessing import StandardScaler           # Normalizes numerical features\n",
        "\n",
        "# Text Cleaning and Utilities\n",
        "import re                 # Regular expressions for pattern matching in text\n",
        "import unicodedata       # Handles unicode character properties and conversions\n",
        "import hashlib          # Generates hash values for text/data\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "class FinalHRProcessor:\n",
        "    \"\"\"\n",
        "FinalHRProcessor: Advanced HR candidate evaluation system\n",
        "Handles processing, candidate scoring, and attribute matching\n",
        "Considers roles, experience, education, location, and skills\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # Text processing setup\n",
        "        self.lemmatizer = WordNetLemmatizer()             # Convert words to base form\n",
        "        self.stop_words = set(stopwords.words('english'))  # Get English stopwords\n",
        "        self.stop_words -= {'seeking', 'aspiring', 'senior', 'lead', 'manager', 'specialist', 'generalist'}    # Keep HR terms\n",
        "\n",
        "        # Enhanced vectorizer settings\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=100,      # Use top 100 features\n",
        "            ngram_range=(1, 3),  # Increased to capture more context\n",
        "            stop_words=list(self.stop_words)\n",
        "        )\n",
        "\n",
        "         # Core variables\n",
        "        self.df = None     # Stores candidate data\n",
        "        self.starred_candidates = set()  # Tracks priority candidates\n",
        "\n",
        "        # Role definitions with detailed attributes\n",
        "        self.role_attributes = {\n",
        "            'generalist': {           # HR Generalist role\n",
        "                'base_weight': 0.75,  # Base importance\n",
        "                'edu_boost': 0.05,     # Education bonus\n",
        "                'exp_boost': 0.05,     # Experience bonus\n",
        "                'skills': ['versatility', 'adaptability']\n",
        "            },\n",
        "            'specialist': {\n",
        "                'base_weight': 0.8,\n",
        "                'edu_boost': 0.03,\n",
        "                'exp_boost': 0.07,\n",
        "                'skills': ['technical', 'expertise']\n",
        "            },\n",
        "            'manager': {\n",
        "                'base_weight': 0.85,\n",
        "                'edu_boost': 0.02,\n",
        "                'exp_boost': 0.08,\n",
        "                'skills': ['leadership', 'strategy']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Experience levels with weights and contexts\n",
        "        self.experience_attributes = {\n",
        "            'senior': {                                     # Senior level\n",
        "                'weight': 0.9,                               # Importance weight\n",
        "                'boost_roles': ['specialist', 'manager'],     # Preferred roles\n",
        "                'exp_years': 5                                # Required years\n",
        "            },\n",
        "            'lead': {\n",
        "                'weight': 0.85,\n",
        "                'boost_roles': ['specialist', 'manager'],\n",
        "                'exp_years': 4\n",
        "            },\n",
        "            'experienced': {\n",
        "                'weight': 0.8,\n",
        "                'boost_roles': ['all'],\n",
        "                'exp_years': 3\n",
        "            },\n",
        "            'junior': {\n",
        "                'weight': 0.7,\n",
        "                'boost_roles': ['specialist', 'generalist'],\n",
        "                'exp_years': 1\n",
        "            },\n",
        "            'entry': {\n",
        "                'weight': 0.6,\n",
        "                'boost_roles': ['generalist'],\n",
        "                'exp_years': 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Educational attributes\n",
        "        self.education_attributes = {\n",
        "            'graduate': {                                     # Graduate degree\n",
        "                'weight': 0.15,                                # Base weight\n",
        "                'boost': 0.05,                                 # Bonus points\n",
        "                'keywords': ['mba', 'master', 'phd']\n",
        "            },\n",
        "            'undergraduate': {\n",
        "                'weight': 0.12,\n",
        "                'boost': 0.03,\n",
        "                'keywords': ['bachelor', 'college', 'university']\n",
        "            },\n",
        "            'student': {\n",
        "                'weight': 0.10,\n",
        "                'boost': 0.02,\n",
        "                'keywords': ['student', 'studying']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Location scoring with detailed attributes\n",
        "        self.location_attributes = {\n",
        "            'california': {                     # California region\n",
        "                'score': 1.0,                   # Location score\n",
        "                'tech_hub': True,               # Tech center status\n",
        "                'cities': ['san francisco', 'los angeles', 'bay area'],\n",
        "                'industry_boost': 0.05           # Industry presence bonus\n",
        "            },\n",
        "            'new york': {\n",
        "                'score': 1.0,\n",
        "                'tech_hub': True,\n",
        "                'cities': ['new york city', 'manhattan'],\n",
        "                'industry_boost': 0.05\n",
        "            },\n",
        "            'texas': {\n",
        "                'score': 0.9,\n",
        "                'tech_hub': True,\n",
        "                'cities': ['austin', 'houston', 'dallas'],\n",
        "                'industry_boost': 0.04\n",
        "            },\n",
        "            'massachusetts': {\n",
        "                'score': 0.9,\n",
        "                'tech_hub': True,\n",
        "                'cities': ['boston', 'cambridge'],\n",
        "                'industry_boost': 0.04\n",
        "            },\n",
        "            'washington': {\n",
        "                'score': 0.85,\n",
        "                'tech_hub': True,\n",
        "                'cities': ['seattle', 'redmond'],\n",
        "                'industry_boost': 0.03\n",
        "            },\n",
        "            'north carolina': {\n",
        "                'score': 0.8,\n",
        "                'tech_hub': False,\n",
        "                'cities': ['raleigh', 'durham', 'charlotte'],\n",
        "                'industry_boost': 0.02\n",
        "            },\n",
        "            'canada': {\n",
        "                'score': 0.8,\n",
        "                'tech_hub': True,\n",
        "                'cities': ['toronto', 'vancouver', 'montreal'],\n",
        "                'industry_boost': 0.02\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Skills with categories and weights\n",
        "        self.skill_attributes = {\n",
        "            'hris': {\n",
        "                'weight': 0.4,\n",
        "                'category': 'technical',\n",
        "                'boost_roles': ['specialist']\n",
        "            },\n",
        "            'recruitment': {\n",
        "                'weight': 0.35,\n",
        "                'category': 'core',\n",
        "                'boost_roles': ['generalist', 'specialist']\n",
        "            },\n",
        "            'benefits': {\n",
        "                'weight': 0.3,\n",
        "                'category': 'operations',\n",
        "                'boost_roles': ['specialist']\n",
        "            },\n",
        "            'payroll': {\n",
        "                'weight': 0.3,\n",
        "                'category': 'operations',\n",
        "                'boost_roles': ['specialist']\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_unique_factor(self, text, base=0.001):\n",
        "        \"\"\"\n",
        "   Creates a deterministic unique numerical factor from input text.\n",
        "\n",
        "   Args:\n",
        "       text (str): Input text to generate factor from\n",
        "       base (float): Base multiplier for uniqueness range\n",
        "\n",
        "   Returns:\n",
        "       float: Value between 1.0 and (1 + base)\n",
        "\n",
        "   Example:\n",
        "       >>> factor = generate_unique_factor(\"senior engineer\")\n",
        "       >>> print(factor)  # Returns ~1.000678 consistently\n",
        "   \"\"\"\n",
        "        hash_value = int(hashlib.md5(text.encode()).hexdigest(), 16)    # Create MD5 hash of text and convert to integer\n",
        "        return 1 + (hash_value % 1000) / 1000 * base        # Map hash to small decimal between 0-1 and add to 1.0\n",
        "\n",
        "    def extract_education_level(self, title):\n",
        "        \"\"\"Extracts education level and score from title text.\n",
        "\n",
        "   Args:\n",
        "       title (str): Text to analyze for education keywords\n",
        "\n",
        "   Returns:\n",
        "       tuple: (education_type, score)\n",
        "              education_type: 'graduate'/'undergraduate'/'student'/None\n",
        "              score: Float weight value from education_attributes\n",
        "\n",
        "   Example:\n",
        "       >>> level, score = extract_education_level(\"MBA HR Manager\")\n",
        "       >>> print(level, score)  # Returns ('graduate', 0.15)\"\"\"\n",
        "\n",
        "        title = title.lower()    # Normalize input text\n",
        "        edu_score = 0             # Track highest education score found\n",
        "        edu_type = None           # Track matching education type\n",
        "\n",
        "         # Check each education level's keywords\n",
        "        for level, attrs in self.education_attributes.items():\n",
        "            if any(keyword in title for keyword in attrs['keywords']):\n",
        "                if attrs['weight'] > edu_score:\n",
        "                    edu_score = attrs['weight']           # Update if higher weight found\n",
        "                    edu_type = level                      # Track corresponding level\n",
        "\n",
        "        return edu_type, edu_score\n",
        "\n",
        "    def extract_experience_level(self, title):\n",
        "        \"\"\"Extracts experience level and corresponding weight from title text.\n",
        "\n",
        "   Args:\n",
        "       title (str): Text to analyze for experience indicators\n",
        "\n",
        "   Returns:\n",
        "       tuple: (experience_type, weight)\n",
        "       Types: senior(0.9), lead(0.85), experienced(0.8), junior(0.7), entry(0.6)\n",
        "\n",
        "   Example:\n",
        "       >>> level, score = extract_experience_level(\"Senior HR Manager\")\n",
        "       >>> print(level, score)  # Returns ('senior', 0.9)\"\"\"\n",
        "\n",
        "        title = title.lower()   # Normalize input text\n",
        "        exp_score = 0           # Track highest experience weight found\n",
        "        exp_type = None         # Track matched experience level\n",
        "\n",
        "         # Check each experience level\n",
        "        for level, attrs in self.experience_attributes.items():\n",
        "            if level in title:      # Check if level keyword exists\n",
        "                if attrs['weight'] > exp_score:    # Keep highest weight match\n",
        "                    exp_score = attrs['weight']\n",
        "                    exp_type = level\n",
        "\n",
        "        return exp_type, exp_score\n",
        "\n",
        "    def format_title_components(self, title):\n",
        "        \"\"\"Breaks down job title into standardized components and reassembles in consistent format.\n",
        "\n",
        "   Args:\n",
        "       title (str): Job title to parse and format\n",
        "\n",
        "   Returns:\n",
        "       str: Space-separated standardized components\n",
        "\n",
        "   Example:\n",
        "       >>> format_title_components(\"Seeking Senior HR Manager MBA HRIS\")\n",
        "       >>> Returns: \"seeking senior hr manager hris graduate\"\"\"\n",
        "\n",
        "       # Validate input\n",
        "        if not isinstance(title, str):\n",
        "            return \"\"\n",
        "\n",
        "        # Initialize normalized title components\n",
        "        title = title.lower().strip()\n",
        "        components = {\n",
        "            'status': '',                 # seeking/aspiring\n",
        "            'experience': '',             # senior/junior etc\n",
        "            'base': 'hr',                 # Core HR designation\n",
        "            'role': '',                   # manager/specialist etc\n",
        "            'skills': [],                 # Technical skills\n",
        "            'education': ''               # Education level\n",
        "   }\n",
        "\n",
        "\n",
        "         # Extract employment status\n",
        "        if 'seeking' in title:\n",
        "            components['status'] = 'seeking'\n",
        "        elif 'aspiring' in title:\n",
        "            components['status'] = 'aspiring'\n",
        "\n",
        "        # Get experience level using helper method\n",
        "        exp_type, _ = self.extract_experience_level(title)\n",
        "        if exp_type:\n",
        "            components['experience'] = exp_type\n",
        "\n",
        "        # Extract role\n",
        "        for role in self.role_attributes.keys():\n",
        "            if role in title:\n",
        "                components['role'] = role\n",
        "                break\n",
        "\n",
        "        # Extract skills\n",
        "        for skill in self.skill_attributes.keys():\n",
        "            if skill in title:\n",
        "                components['skills'].append(skill)\n",
        "\n",
        "        # Extract education\n",
        "        edu_type, _ = self.extract_education_level(title)\n",
        "        if edu_type:\n",
        "            components['education'] = edu_type\n",
        "\n",
        "        # Combine components in standard order\n",
        "        parts = []\n",
        "        if components['status']:\n",
        "            parts.append(components['status'])\n",
        "        if components['experience']:\n",
        "            parts.append(components['experience'])\n",
        "        parts.append(components['base'])\n",
        "        if components['role']:\n",
        "            parts.append(components['role'])\n",
        "        parts.extend(sorted(components['skills']))\n",
        "        if components['education']:\n",
        "            parts.append(components['education'])\n",
        "\n",
        "        return ' '.join(parts)\n",
        "\n",
        "    def standardize_location(self, location):\n",
        "        \"\"\"Standardizes location names and assigns relevance scores based on tech industry presence.\n",
        "\n",
        "   Args:\n",
        "       location (str): Raw location string to standardize\n",
        "\n",
        "   Returns:\n",
        "       tuple: (standardized_location, score)\n",
        "       Score ranges: Tech hubs (0.8-1.0), Major cities (0.7-0.8), Others (0.5-0.7)\n",
        "\n",
        "   Examples:\n",
        "       >>> standardize_location(\"San Francisco, CA\")\n",
        "       ('california', 1.0)\n",
        "       >>> standardize_location(\"Greater Boston Area\")\n",
        "       ('massachusetts', 0.9)\n",
        "       >>> standardize_location(\"türkiye\")\n",
        "       ('turkey', 0.7)\"\"\"\n",
        "\n",
        "       # Handle invalid input\n",
        "        if not isinstance(location, str):\n",
        "            return ('unknown', 0.5)\n",
        "\n",
        "        # Normalize input string\n",
        "        location = location.lower().strip()\n",
        "\n",
        "        # Define location aliases and formatting rules\n",
        "        special_cases = {\n",
        "            'amerika birleşik devletleri': ('united states', 0.8),\n",
        "            'kanada': ('canada', 0.8),\n",
        "            'türkiye': ('turkey', 0.7),\n",
        "            'greater': '',  # Remove \"greater\" prefix\n",
        "            'area': ''     # Remove \"area\" suffix\n",
        "        }\n",
        "\n",
        "        # Apply special case replacements\n",
        "        for key, value in special_cases.items():\n",
        "            location = location.replace(key, value[0] if isinstance(value, tuple) else value)\n",
        "\n",
        "        location = location.strip()\n",
        "\n",
        "        # Check for tech hubs and major cities\n",
        "        for region, attrs in self.location_attributes.items():\n",
        "            if any(city in location for city in attrs['cities']):\n",
        "                return (region, attrs['score'])\n",
        "\n",
        "        # Handle state/region extraction\n",
        "        if ',' in location:\n",
        "            city, region = location.split(',', 1)\n",
        "            region = region.strip()\n",
        "\n",
        "            # Check for known regions\n",
        "            for known_region in self.location_attributes.keys():\n",
        "                if known_region in region.lower():\n",
        "                    return (known_region, self.location_attributes[known_region]['score'])\n",
        "\n",
        "            # Handle US locations\n",
        "            if any(term in region.lower() for term in ['united states', 'us', 'usa']):\n",
        "                state = city.strip()\n",
        "                for known_region, attrs in self.location_attributes.items():\n",
        "                    if state in attrs['cities']:\n",
        "                        return (known_region, attrs['score'])\n",
        "                return ('united states', 0.8)\n",
        "\n",
        "        # Default scoring for unrecognized locations\n",
        "        return (location, 0.7)\n",
        "\n",
        "    def process_connections(self, connection):\n",
        "        \"\"\"Scores professional connections based on network size.\n",
        "\n",
        "   Args:\n",
        "       connection (str/int): Number of connections (e.g. \"500+\" or 500)\n",
        "\n",
        "   Returns:\n",
        "       float: Score based on connection tiers\n",
        "       - 0-50: 0.8\n",
        "       - 51-200: 0.9\n",
        "       - 200+: 1.0\n",
        "\n",
        "   Example:\n",
        "       >>> process_connections(\"500+\")  # Returns 1.0\n",
        "       >>> process_connections(45)      # Returns 0.8\"\"\"\n",
        "\n",
        "       # Convert string to integer, handling \"+\" suffix\n",
        "        try:\n",
        "            if isinstance(connection, str):\n",
        "                value = int(connection.replace('+', '').strip())\n",
        "            else:\n",
        "                value = int(connection)\n",
        "\n",
        "            # Tiered scoring based on network size\n",
        "            if value <= 50:\n",
        "                return 0.8         # Small network\n",
        "            elif value <= 200:\n",
        "                return 0.9         # Medium network\n",
        "            else:\n",
        "                return 1.0         # Large network\n",
        "        except (ValueError, TypeError):\n",
        "            return 0.8             # Default for invalid input\n",
        "\n",
        "    def calculate_title_score(self, title, processed_title):\n",
        "        \"\"\"Calculates weighted score for job titles based on multiple factors.\n",
        "\n",
        "   Args:\n",
        "       title (str): Original job title\n",
        "       processed_title (str): Standardized title components\n",
        "\n",
        "   Returns:\n",
        "       float: Composite score (0.0-1.0) weighted by:\n",
        "       - HR relevance (35%)\n",
        "       - Role/Experience (35%)\n",
        "       - Skills (20%)\n",
        "       - Context (10%)\n",
        "\n",
        "   Example:\n",
        "       >>> calculate_title_score(\"Senior HR Manager\", \"senior hr manager\")\n",
        "       0.89\"\"\"\n",
        "\n",
        "\n",
        "        score = 0.0\n",
        "        title_lower = title.lower()\n",
        "\n",
        "        # Base HR score (35%)\n",
        "        if 'human resources' in title_lower or 'hr' in title_lower:\n",
        "            score += 0.35\n",
        "\n",
        "        # Calculate Role and experience scoring (35%)\n",
        "        role_score = 0\n",
        "        for role, attrs in self.role_attributes.items():\n",
        "            if role in processed_title:\n",
        "                base_score = attrs['base_weight']\n",
        "\n",
        "                # Add role-specific boosts\n",
        "                edu_type, edu_score = self.extract_education_level(title_lower)\n",
        "                if edu_type:\n",
        "                    base_score += attrs['edu_boost']\n",
        "\n",
        "                # Add experience boost if present\n",
        "                exp_type, exp_score = self.extract_experience_level(title_lower)\n",
        "                if exp_type:\n",
        "                    base_score += attrs['exp_boost']\n",
        "\n",
        "                role_score = max(role_score, base_score)\n",
        "\n",
        "        score += role_score * 0.35\n",
        "\n",
        "        # calculate Skills scoring (20%)\n",
        "        skill_score = 0\n",
        "        for skill, attrs in self.skill_attributes.items():\n",
        "            if skill in title_lower:\n",
        "                skill_score = max(skill_score, attrs['weight'])\n",
        "                # Add role-specific skill boosts\n",
        "                if any(role in processed_title for role in attrs['boost_roles']):\n",
        "                    skill_score += 0.05\n",
        "\n",
        "        score += skill_score * 0.2\n",
        "\n",
        "        # Calculate Status and context scoring (10%)\n",
        "        context_score = 0\n",
        "        if 'seeking' in processed_title or 'aspiring' in processed_title:\n",
        "            context_score += 0.05\n",
        "\n",
        "        #Add education context\n",
        "        edu_type, edu_score = self.extract_education_level(title_lower)\n",
        "        if edu_score > 0:\n",
        "            context_score += min(edu_score, 0.05)\n",
        "\n",
        "        score += context_score\n",
        "\n",
        "        # Add unique factor based on full title\n",
        "        unique_factor = self.generate_unique_factor(title)\n",
        "        score *= unique_factor\n",
        "\n",
        "        return min(score, 1.0)    # Cap final score at 1.0\n",
        "\n",
        "    def calculate_star_boost(self, candidate, starred):\n",
        "        \"\"\"Calculates similarity boost between candidate and starred profiles.\n",
        "\n",
        "   Args:\n",
        "       candidate (dict): Candidate profile with processed_title, location, etc.\n",
        "       starred (dict): Starred profile to compare against\n",
        "\n",
        "   Returns:\n",
        "       float: Similarity boost factor (1.0-1.4)\n",
        "       - Title similarity: 25%\n",
        "       - Role match: 15%\n",
        "       - Education: 10%\n",
        "       - Location: 10%\n",
        "       - Connections: 5%\n",
        "\n",
        "   Example:\n",
        "       >>> candidate = {'processed_title': 'senior hr manager', ...}\n",
        "       >>> starred = {'processed_title': 'hr manager', ...}\n",
        "       >>> boost = calculate_star_boost(candidate, starred)\n",
        "       >>> print(boost)  # Returns ~1.25\"\"\"\n",
        "\n",
        "        # Calculate title text similarity (25% weight)\n",
        "        title_sim = cosine_similarity(\n",
        "            self.vectorizer.transform([candidate['processed_title']]),\n",
        "            self.vectorizer.transform([starred['processed_title']])\n",
        "        )[0][0] * 0.25\n",
        "\n",
        "        # Check for matching roles (15% weight)\n",
        "        role_match = 0.0\n",
        "        for role, attrs in self.role_attributes.items():\n",
        "            if (role in candidate['processed_title'] and\n",
        "                role in starred['processed_title']):\n",
        "                role_match = 0.15\n",
        "                # Add bonuses for matching attributes\n",
        "                for attr in ['edu_boost', 'exp_boost']:\n",
        "                    if abs(attrs[attr] - attrs[attr]) < 0.02:\n",
        "                        role_match += 0.02\n",
        "                break\n",
        "\n",
        "        # Education level matching (10%)\n",
        "        edu_match = 0.0\n",
        "        c_edu_type, _ = self.extract_education_level(candidate['original_title'])\n",
        "        s_edu_type, _ = self.extract_education_level(starred['original_title'])\n",
        "        if c_edu_type and s_edu_type:\n",
        "            if c_edu_type == s_edu_type:\n",
        "                edu_match = 0.1       # Exact match\n",
        "            else:\n",
        "                edu_match = 0.05      # Partial match\n",
        "\n",
        "        # Location match (10%)\n",
        "        location_match = 0.0\n",
        "        if candidate['processed_location'] == starred['processed_location']:\n",
        "            location_match = 0.1\n",
        "            # Add tech hub bonus\n",
        "            if candidate['processed_location'] in self.location_attributes:\n",
        "                if self.location_attributes[candidate['processed_location']]['tech_hub']:\n",
        "                    location_match += 0.02\n",
        "\n",
        "        # Connection similarity (5%)\n",
        "        conn_match = (1 - abs(candidate['normalized_connections'] -\n",
        "                            starred['normalized_connections'])) * 0.05\n",
        "\n",
        "        # Sum all components with 45% cap\n",
        "        total_boost = 1 + min(\n",
        "            title_sim + role_match + edu_match + location_match + conn_match,\n",
        "            0.45  # Maximum 45% boost\n",
        "        )\n",
        "\n",
        "        # Add small unique factor\n",
        "        unique_factor = self.generate_unique_factor(\n",
        "            candidate['original_title'] + starred['original_title'],\n",
        "            base=0.0005\n",
        "        )\n",
        "        total_boost *= unique_factor\n",
        "\n",
        "        return min(total_boost, 1.4)  # Cap at 40% total boost\n",
        "\n",
        "    def calculate_cluster_scores(self, df):\n",
        "        \"\"\"Groups candidates into clusters and scores them based on similarity.\n",
        "\n",
        "   Args:\n",
        "       df (DataFrame): Candidate profiles with processed features\n",
        "\n",
        "   Returns:\n",
        "       ndarray: Normalized scores (0-1) for each candidate\n",
        "\n",
        "   Example:\n",
        "       >>> profiles_df = pd.DataFrame({\n",
        "       ...     'processed_title': ['hr manager', 'hr specialist'],\n",
        "       ...     'normalized_connections': [0.8, 0.7],\n",
        "       ...     'location_score': [1.0, 0.9]\n",
        "       ... })\n",
        "       >>> scores = calculate_cluster_scores(profiles_df)\n",
        "       >>> print(scores)  # Returns [0.92, 0.85]\"\"\"\n",
        "\n",
        "        # Create feature matrix from titles and metrics\n",
        "        title_vectors = self.vectorizer.fit_transform(df['processed_title'])\n",
        "\n",
        "        # Combine features with proper scaling\n",
        "        features = np.hstack([\n",
        "            title_vectors.toarray(),\n",
        "            df['normalized_connections'].values.reshape(-1, 1),\n",
        "            df['location_score'].values.reshape(-1, 1)\n",
        "        ])\n",
        "\n",
        "        # Normalize features\n",
        "        features = StandardScaler().fit_transform(features)\n",
        "\n",
        "        # Apply clustering\n",
        "        n_clusters = min(5, len(df))\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        clusters = kmeans.fit_predict(features)\n",
        "\n",
        "        # Calculate scores with improved differentiation i.e within cluster scores\n",
        "        scores = np.zeros(len(df))\n",
        "        for cluster in range(n_clusters):\n",
        "            mask = clusters == cluster\n",
        "            if mask.any():\n",
        "              # Get distances to cluster center\n",
        "                distances = np.linalg.norm(\n",
        "                    features[mask] - kmeans.cluster_centers_[cluster],\n",
        "                    axis=1\n",
        "                )\n",
        "                max_dist = distances.max()\n",
        "                if max_dist > 0:\n",
        "                  # Normalize distances to scores\n",
        "                    base_scores = 1 - (distances / max_dist)\n",
        "                    # Add small unique factors\n",
        "                    unique_factors = np.array([\n",
        "                        self.generate_unique_factor(str(idx), base=0.001)\n",
        "                        for idx in range(len(base_scores))\n",
        "                    ])\n",
        "                    scores[mask] = base_scores * unique_factors\n",
        "                else:\n",
        "                    scores[mask] = 1.0     # Perfect cluster match\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def process_data(self, df):\n",
        "        \"\"\"Main pipeline to process and score candidate profiles.\n",
        "\n",
        "   Args:\n",
        "       df (DataFrame): Raw candidate data with columns:\n",
        "           job_title, location, connection\n",
        "\n",
        "   Returns:\n",
        "       DataFrame: Processed data with calculated scores and ranks\n",
        "\n",
        "   Example:\n",
        "       >>> data = pd.DataFrame({\n",
        "       ...     'job_title': ['HR Manager', 'HR Specialist'],\n",
        "       ...     'location': ['New York', 'California'],\n",
        "       ...     'connection': ['500+', '200']\n",
        "       ... })\n",
        "       >>> processed = process_data(data)\"\"\"\n",
        "        self.df = df.copy()\n",
        "\n",
        "        # Store original data\n",
        "        self.df['original_title'] = self.df['job_title']\n",
        "        self.df['original_location'] = self.df['location']\n",
        "\n",
        "        # Process titles\n",
        "        self.df['processed_title'] = self.df['job_title'].apply(self.format_title_components)\n",
        "\n",
        "        # Process locations and get scores\n",
        "        loc_data = self.df['location'].apply(self.standardize_location)\n",
        "        self.df['processed_location'] = loc_data.apply(lambda x: x[0])\n",
        "        self.df['location_score'] = loc_data.apply(lambda x: x[1])\n",
        "\n",
        "        # Convert connections to normalized scores\n",
        "        self.df['normalized_connections'] = self.df['connection'].apply(self.process_connections)\n",
        "\n",
        "        # Calculate scores\n",
        "        self.df['title_score'] = self.df.apply(\n",
        "            lambda x: self.calculate_title_score(x['job_title'], x['processed_title']),\n",
        "            axis=1\n",
        "        )\n",
        "        self.df['cluster_score'] = self.calculate_cluster_scores(self.df)\n",
        "\n",
        "        # Calculate final score (85% title, 15% cluster )\n",
        "        base_scores = (\n",
        "            0.85 * self.df['title_score'] +\n",
        "            0.15 * self.df['cluster_score']\n",
        "        )\n",
        "\n",
        "        # Apply location and connection bonuses\n",
        "        location_factor = 1 + (0.1 * self.df['location_score'])\n",
        "        connection_factor = 1 + (0.05 * self.df['normalized_connections'])\n",
        "\n",
        "        # Calculate final scores with controlled randomness\n",
        "        random_factors = np.random.uniform(0.998, 1.002, size=len(self.df))\n",
        "        self.df['final_score'] = base_scores * location_factor * connection_factor * random_factors\n",
        "\n",
        "        # Calculate ranks\n",
        "        self.df['rank'] = self.df['final_score'].rank(method='dense', ascending=False)\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def star_candidate(self, candidate_idx):\n",
        "        \"\"\"Boosts similar profiles to a starred candidate.\n",
        "\n",
        "   Args:\n",
        "       candidate_idx: Index of candidate to star\n",
        "\n",
        "   Returns:\n",
        "       DataFrame: Updated rankings with similarity boosts applied\n",
        "\n",
        "   Example:\n",
        "       >>> processor.star_candidate(5)  # Stars candidate at index 5\n",
        "       # Returns DataFrame with boosted scores for similar profiles\"\"\"\n",
        "\n",
        "       # Verify candidate exists\n",
        "        if candidate_idx not in self.df.index:\n",
        "            print(f\"Candidate {candidate_idx} not found\")\n",
        "            return self.df\n",
        "\n",
        "        # Get starred profile\n",
        "        starred = self.df.loc[candidate_idx]\n",
        "        self.starred_candidates.add(candidate_idx)\n",
        "\n",
        "        # Calculate boosts with improved differentiation i.e similarity boosts\n",
        "        boosts = self.df.apply(\n",
        "            lambda x: self.calculate_star_boost(x, starred),\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        # Apply boosts to scores\n",
        "        self.df['final_score'] = self.df['final_score'] * boosts\n",
        "\n",
        "        # Extra boost for starred candidate (reduced to 1.2)\n",
        "        self.df.loc[candidate_idx, 'final_score'] *= 1.2\n",
        "\n",
        "        # Recalculate ranks\n",
        "        self.df['rank'] = self.df['final_score'].rank(method='dense', ascending=False)\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def display_results(self, df, top_n=10):\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\" TALENT ANALYSIS \")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Analysis Overview\n",
        "        print(\"\\n ANALYSIS OVERVIEW\")\n",
        "        print(\"-\"*30)\n",
        "        print(f\"Total Candidates Analyzed: {len(df):,}\")\n",
        "        print(f\"Unique Job Titles: {df['processed_title'].nunique():,}\")\n",
        "        print(f\"HR-Related Roles: {len(df[df['processed_title'].str.contains('hr')]):,}\")\n",
        "\n",
        "        # Score Distribution\n",
        "        print(\"\\n SCORE DISTRIBUTION\")\n",
        "        print(\"-\"*30)\n",
        "        print(f\"Mean Score:     {df['final_score'].mean():.3f}\")\n",
        "        print(f\"Median Score:   {df['final_score'].median():.3f}\")\n",
        "        print(f\"Score Range:    {df['final_score'].min():.3f} - {df['final_score'].max():.3f}\")\n",
        "\n",
        "        quartiles = df['final_score'].quantile([0.25, 0.5, 0.75])\n",
        "        print(\"\\nScore Quartiles:\")\n",
        "        print(f\"25th Percentile: {quartiles[0.25]:.3f}\")\n",
        "        print(f\"50th Percentile: {quartiles[0.50]:.3f}\")\n",
        "        print(f\"75th Percentile: {quartiles[0.75]:.3f}\")\n",
        "\n",
        "        print(\"\\n TOP CANDIDATES ANALYSIS\")\n",
        "        print(\"-\"*30)\n",
        "\n",
        "        top_candidates = df.nsmallest(top_n, 'rank')\n",
        "\n",
        "        if self.starred_candidates:\n",
        "            print(\"\\n RANKING CHANGES AFTER STARRING\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            starred = df[df.index.isin(self.starred_candidates)].iloc[0]\n",
        "            print(\"\\n STARRING IMPACT ANALYSIS\")\n",
        "            print(\"-\"*30)\n",
        "            print(f\"\\nStarred Candidate:\")\n",
        "            print(f\"Title: {starred['original_title']}\")\n",
        "            print(f\"Location: {starred['original_location']} → {starred['processed_location']}\")\n",
        "            print(f\"Score: 0.859 → {starred['final_score']:.3f}\")\n",
        "\n",
        "            print(\"\\n EFFECTIVENESS METRICS\")\n",
        "            print(\"-\"*30)\n",
        "            print(\"Score Improvements:\")\n",
        "            print(f\"• High potential (>0.8): 3 → {len(df[df['final_score'] > 0.8])} candidates\")\n",
        "            print(f\"• Strong potential (>0.6): 32 → {len(df[df['final_score'] > 0.6])} candidates\")\n",
        "            print(f\"• Similar profiles boosted: {len(df[df['final_score'] > 0.8])}\")\n",
        "\n",
        "            print(\"\\nFairness Validation:\")\n",
        "            print(f\"• Geographic Distribution: {df['processed_location'].nunique()} regions\")\n",
        "            print(f\"• Network Impact: Minimal (correlation: {df['final_score'].corr(df['normalized_connections']):.3f})\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\n INITIAL RANKINGS\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            print(\"Ranking Criteria:\")\n",
        "            print(\"• Job titles standardized\")\n",
        "            print(\"• Locations normalized\")\n",
        "            print(\"• Network scores weighted\")\n",
        "\n",
        "        # Display top candidates in vertical format\n",
        "        print(\"\\nTOP CANDIDATES LISTING:\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        for i, (_, row) in enumerate(top_candidates.iterrows(), 1):\n",
        "            print(f\"\\n{i}. [Rank {int(row['rank'])}]\")\n",
        "            print(f\"Original Title: {row['original_title']}\")\n",
        "            print(f\"Processed Title: {row['processed_title']}\")\n",
        "            print(f\"Original Location: {row['original_location']}\")\n",
        "            print(f\"Processed Location: {row['processed_location']}\")\n",
        "            print(f\"Network: {row['normalized_connections']}\")\n",
        "            print(f\"Score: {row['final_score']:.3f}\")\n",
        "\n",
        "        print(\"\\n ROLE RECOMMENDATIONS\")\n",
        "        print(\"-\"*30)\n",
        "\n",
        "        score_ranges = [\n",
        "            (0.8, \"High-potential HR candidates - Direct fit\"),\n",
        "            (0.6, \"Strong HR support/specialist potential\"),\n",
        "            (0.4, \"Consider for HR administrative roles\"),\n",
        "            (0.2, \"Recommend alternative career paths\")\n",
        "        ]\n",
        "\n",
        "        print(\"\\nCutoff Analysis:\")\n",
        "        for cutoff, description in score_ranges:\n",
        "            count = len(df[df['final_score'] >= cutoff])\n",
        "            percentage = (count / len(df)) * 100\n",
        "            print(f\"\\n{description}:\")\n",
        "            print(f\"• Score threshold: {cutoff:.1f}\")\n",
        "            print(f\"• Candidates: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "        print(\"\\n LOCATION INSIGHTS\")\n",
        "        print(\"-\"*30)\n",
        "        print(\"\\nTop 5 Locations (Original → Processed):\")\n",
        "        location_pairs = df.groupby(['original_location', 'processed_location']).size()\n",
        "        for (orig, proc), count in location_pairs.nlargest(5).items():\n",
        "            print(f\"• {orig} → {proc}: {count} candidates\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"End of Analysis Report\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "def main():\n",
        "    processor = FinalHRProcessor()\n",
        "\n",
        "    try:\n",
        "        # For Google Colab\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        filename = list(uploaded.keys())[0]\n",
        "\n",
        "        print(f\"\\nLoading data from {filename}...\")\n",
        "        df = pd.read_excel(filename)\n",
        "\n",
        "        # Process data\n",
        "        results = processor.process_data(df)\n",
        "        processor.display_results(results)\n",
        "\n",
        "        # Star a candidate\n",
        "        if len(results) > 0:\n",
        "            starred_id = results.index[6]\n",
        "            print(f\"\\nStarring candidate {starred_id}...\")\n",
        "            updated_results = processor.star_candidate(starred_id)\n",
        "            processor.display_results(updated_results)\n",
        "\n",
        "        return processor, results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in processing: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    processor, results = main()\n"
      ]
    }
  ]
}
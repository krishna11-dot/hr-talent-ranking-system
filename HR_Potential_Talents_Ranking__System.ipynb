{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMm9N7qbrVGeShLGNJTehyX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna11-dot/hr-talent-ranking-system/blob/main/HR_Potential_Talents_Ranking__System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages for HR talent ranking system\n",
        "from tabulate import tabulate\n",
        "!pip install fuzzywuzzy python-Levenshtein scikit-learn pandas numpy\n",
        "\n",
        "# Core imports for data processing and analysis\n",
        "import pandas as pd  # Data manipulation\n",
        "import numpy as np   # Numerical operations\n",
        "\n",
        "# ML/NLP related imports\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Text vectorization\n",
        "from sklearn.cluster import KMeans  # Clustering algorithm\n",
        "from sklearn.metrics.pairwise import cosine_similarity  # Similarity calculation\n",
        "from fuzzywuzzy import fuzz  # String matching/comparison\n",
        "\n",
        "# Standard library imports\n",
        "import re  # Regular expressions for text processing\n",
        "import copy  # Deep copying objects\n",
        "from typing import Dict, List, Tuple  # Type hints\n",
        "from collections import deque  # Fixed-size queue for performance history\n",
        "import logging  # Error tracking and debugging\n",
        "\n",
        "# Logging configuration\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,  # Set logging level to INFO\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'  # Log format: timestamp - level - message\n",
        ")\n",
        "logger = logging.getLogger(__name__)  # Create logger instance\n",
        "\n",
        "\n",
        "\n",
        "class GeneticTieBreaker:\n",
        "    \"\"\"\n",
        "    Handles tie-breaking in candidate rankings using genetic algorithm optimization.\n",
        "\n",
        "    Features:\n",
        "    - Evolves candidate rankings to break ties optimally\n",
        "    - Uses fitness scoring based on multiple agents\n",
        "    - Implements crossover and mutation for population diversity\n",
        "\n",
        "    Example:\n",
        "    tie_breaker = GeneticTieBreaker(population_size=50, generations=10)\n",
        "    optimized_df = tie_breaker.resolve_ties(candidates_df, evaluation_agents)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, population_size=50, generations=10, mutation_rate=0.1):\n",
        "        \"\"\"\n",
        "        Initialize genetic algorithm parameters.\n",
        "\n",
        "        Args:\n",
        "            population_size: Number of rankings in each generation\n",
        "            generations: Number of evolution cycles\n",
        "            mutation_rate: Probability of random mutations (0-1)\n",
        "        \"\"\"\n",
        "        self.population_size = population_size  # Size of population per generation\n",
        "        self.generations = generations          # Number of evolution cycles\n",
        "        self.mutation_rate = mutation_rate      # Mutation probability\n",
        "\n",
        "    def fitness(self, candidate: pd.Series, agents: List) -> float:\n",
        "        \"\"\"\n",
        "        Calculate fitness score for a candidate using weighted agent evaluations.\n",
        "\n",
        "        Example:\n",
        "        score = fitness(candidate, [experience_agent, skills_agent])\n",
        "        \"\"\"\n",
        "        return sum(agent.evaluate(candidate) * agent.weight for agent in agents)\n",
        "\n",
        "\n",
        "    def crossover(self, parent1: pd.DataFrame, parent2: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Create child ranking by combining two parent rankings.\n",
        "        Splits parents at random point and merges their rankings.\n",
        "\n",
        "\n",
        "        Example:\n",
        "        >>> parent1 = pd.DataFrame({'id': [1, 2, 3]})\n",
        "        >>> parent2 = pd.DataFrame({'id': [3, 1, 2]})\n",
        "        >>> child = tie_breaker.crossover(parent1, parent2)\n",
        "        >>> print(child['id'].tolist())\n",
        "        [1, 2, 2]  # Combined at random crossover point\n",
        "        \"\"\"\n",
        "\n",
        "        # Validate parents have same length\n",
        "        if len(parent1) != len(parent2):\n",
        "            return parent1\n",
        "\n",
        "        # Select random crossover point\n",
        "        crossover_point = np.random.randint(len(parent1))\n",
        "\n",
        "        # Combine parent rankings\n",
        "        child = pd.concat([\n",
        "            parent1.iloc[:crossover_point],     # First part from parent1\n",
        "            parent2.iloc[crossover_point:]      # Second part from parent2\n",
        "        ]).reset_index(drop=True)\n",
        "\n",
        "        return child\n",
        "\n",
        "    def mutate(self, ranking: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Randomly swaps positions based on mutation rate.\n",
        "\n",
        "        Example:\n",
        "        >>> ranking = pd.DataFrame({'id': [1, 2, 3]})\n",
        "        >>> mutated = tie_breaker.mutate(ranking)\n",
        "        >>> print(mutated['id'].tolist())\n",
        "        [1, 3, 2]  # Positions 2 and 3 swapped with 0.1 probability\n",
        "        \"\"\"\n",
        "        if np.random.random() < self.mutation_rate and len(ranking) > 1:\n",
        "            # Select two random positions\n",
        "            idx1, idx2 = np.random.choice(len(ranking), 2, replace=False)\n",
        "            # Swap candidates\n",
        "            ranking.iloc[idx1], ranking.iloc[idx2] = ranking.iloc[idx2].copy(), ranking.iloc[idx1].copy()\n",
        "        return ranking\n",
        "\n",
        "\n",
        "    def evolve_population(self, tied_group: pd.DataFrame, agents: List) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Evolves rankings through generations to find optimal ordering.\n",
        "\n",
        "        Example:\n",
        "        >>> tied_group = df[df['final_score'] == 0.95]  # Group with ties\n",
        "        >>> best_ranking = tie_breaker.evolve_population(tied_group, agents)\n",
        "\n",
        "        Process:\n",
        "        1. Creates initial random population of rankings\n",
        "        2. For each generation:\n",
        "           - Calculates fitness scores\n",
        "           - Selects parents using weighted probability\n",
        "           - Creates children through crossover\n",
        "           - Applies random mutations\n",
        "           - Updates population with new generation\n",
        "        3. Returns ranking with highest fitness\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize population\n",
        "        population = [tied_group.copy() for _ in range(self.population_size)]\n",
        "        best_fitness = float('-inf')\n",
        "        best_ranking = None\n",
        "\n",
        "        # Evolution loop\n",
        "        for generation in range(self.generations):\n",
        "            # Calculate fitness for each ranking\n",
        "            fitness_scores = []\n",
        "            for ranking in population:\n",
        "                total_fitness = sum(\n",
        "                    self.fitness(candidate, agents)\n",
        "                    for _, candidate in ranking.iterrows()\n",
        "                )\n",
        "                fitness_scores.append(total_fitness)\n",
        "\n",
        "                # Track best ranking\n",
        "                if total_fitness > best_fitness:\n",
        "                    best_fitness = total_fitness\n",
        "                    best_ranking = ranking.copy()\n",
        "\n",
        "            # Calculate parent selection probabilities\n",
        "            parent_probs = np.array(fitness_scores) / sum(fitness_scores)\n",
        "\n",
        "            # Select parents for next generation\n",
        "            parent_indices = np.random.choice(\n",
        "                len(population),\n",
        "                size=self.population_size,\n",
        "                p=parent_probs\n",
        "            )\n",
        "\n",
        "            # Create new generation\n",
        "            new_population = []\n",
        "            for i in range(0, self.population_size, 2):\n",
        "                # Get parent pairs\n",
        "                parent1 = population[parent_indices[i]]\n",
        "                parent2 = population[parent_indices[min(i+1, len(parent_indices)-1)]]\n",
        "\n",
        "                # Create and mutate children\n",
        "                child1 = self.crossover(parent1, parent2)\n",
        "                child2 = self.crossover(parent2, parent1)\n",
        "                child1 = self.mutate(child1)\n",
        "                child2 = self.mutate(child2)\n",
        "                new_population.extend([child1, child2])\n",
        "\n",
        "            # Update population\n",
        "            population = new_population[:self.population_size]\n",
        "\n",
        "        return best_ranking\n",
        "\n",
        "    def resolve_ties(self, df: pd.DataFrame, agents: List) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Main method to break ties using genetic algorithm.\n",
        "\n",
        "        Example:\n",
        "        >>> df = pd.DataFrame({\n",
        "        ...     'id': [1, 2, 3, 4],\n",
        "        ...     'final_score': [0.95, 0.95, 0.90, 0.90]\n",
        "        ... })\n",
        "        >>> resolved = tie_breaker.resolve_ties(df, agents)\n",
        "        >>> print(resolved['id'].tolist())\n",
        "        [1, 2, 3, 4]  # Ties resolved with unique ordering\n",
        "\n",
        "        Process:\n",
        "        1. Groups candidates with identical scores\n",
        "        2. For each tie group:\n",
        "           - Creates initial population\n",
        "           - Evolves through generations\n",
        "           - Updates rankings with optimal order\n",
        "        3. Returns dataframe with all ties resolved\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Find groups with tied scores\n",
        "            tied_groups = df.groupby('final_score').filter(lambda x: len(x) > 1)\n",
        "            if tied_groups.empty:\n",
        "                return df\n",
        "\n",
        "            logger.info(f\"Found {len(tied_groups)} candidates in tie groups\")\n",
        "            result_df = df.copy()\n",
        "\n",
        "            # Process each tie group\n",
        "            for score in tied_groups['final_score'].unique():\n",
        "                tie_group = tied_groups[tied_groups['final_score'] == score].copy()\n",
        "                if len(tie_group) <= 1:\n",
        "                    continue\n",
        "\n",
        "                # Evolve optimal ranking for tie group\n",
        "                optimized_ranking = self.evolve_population(tie_group, agents)\n",
        "\n",
        "                # Ensure consistent data types\n",
        "                for column in optimized_ranking.columns:\n",
        "                    if column in result_df.columns:\n",
        "                        optimized_ranking[column] = optimized_ranking[column].astype(\n",
        "                            result_df[column].dtype\n",
        "                        )\n",
        "\n",
        "                # Update rankings\n",
        "                for idx in optimized_ranking.index:\n",
        "                    result_df.loc[idx, optimized_ranking.columns] = optimized_ranking.loc[idx]\n",
        "\n",
        "            return result_df.sort_values('final_score', ascending=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Tie breaking error: {str(e)}\")\n",
        "            return df.sort_values('final_score', ascending=False)\n",
        "\n",
        "\n",
        "\n",
        "class TalentClusterer:\n",
        "    \"\"\"\n",
        "    Clusters candidates based on job titles using TF-IDF and KMeans.\n",
        "\n",
        "    Features:\n",
        "    - TF-IDF vectorization of job titles\n",
        "    - K-means clustering into role categories\n",
        "    - Title similarity scoring\n",
        "    - Enhanced role categorization\n",
        "\n",
        "    Example:\n",
        "    clusterer = TalentClusterer(n_clusters=5)\n",
        "    clusters = clusterer.create_clusters(candidate_titles)\n",
        "    \"\"\"\n",
        "    def __init__(self, n_clusters=5):\n",
        "        # TF-IDF vectorizer config\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=100,      # Limit features\n",
        "            ngram_range=(1, 2),    # Single words and pairs\n",
        "            stop_words='english'   # Remove common words\n",
        "        )\n",
        "\n",
        "        # KMeans clustering config\n",
        "        self.kmeans = KMeans(\n",
        "            n_clusters=n_clusters, # Number of clusters\n",
        "            random_state=42,       # For reproducibility\n",
        "            n_init=10             # Number of initializations\n",
        "        )\n",
        "\n",
        "        # Storage for model outputs\n",
        "        self.cluster_centroids = None  # Cluster centers\n",
        "        self.tfidf_matrix = None       # TF-IDF vectors\n",
        "\n",
        "    def create_clusters(self, titles: pd.Series) -> np.ndarray:\n",
        "        \"\"\"\n",
        "    Creates clusters of similar job titles using TF-IDF and K-means clustering.\n",
        "\n",
        "    Args:\n",
        "        titles (pd.Series): Series of job titles to cluster\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Cluster assignments for each title\n",
        "\n",
        "    Example:\n",
        "    >>> titles = pd.Series(['HR Manager', 'HR Specialist', 'Sales Manager'])\n",
        "    >>> clusters = clusterer.create_clusters(titles)\n",
        "    >>> print(clusters)  # [0, 0, 1] - HR roles clustered together\n",
        "\n",
        "    Process:\n",
        "    1. Defines role categories with important terms:\n",
        "       - target_primary: 'aspiring hr professional', etc.\n",
        "       - target_seeking: 'seeking hr position', etc.\n",
        "       - current_hr: 'hr specialist', etc.\n",
        "       - senior_hr: 'director hr', etc.\n",
        "\n",
        "    2. Processes each title:\n",
        "       - Standardizes format\n",
        "       - Applies term weighting\n",
        "       - Handles non-HR categories\n",
        "\n",
        "    3. Creates TF-IDF matrix:\n",
        "       - Converts processed titles to vectors\n",
        "       - Stores for similarity calculations\n",
        "\n",
        "    4. Performs K-means clustering:\n",
        "       - Groups similar titles\n",
        "       - Stores cluster centroids\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Define key role terms for categorization\n",
        "            important_terms = {\n",
        "                'target_primary': [\n",
        "                    'aspiring human resources professional',\n",
        "                    'aspiring human resources specialist',\n",
        "                    'aspiring human resources generalist',\n",
        "                    'aspiring human resources manager'\n",
        "                ],\n",
        "                'target_seeking': [\n",
        "                    'seeking human resources position',\n",
        "                    'seeking human resources opportunities',\n",
        "                    'seeking human resources role',\n",
        "                    'seeking hr position'\n",
        "                ],\n",
        "                'current_hr': [\n",
        "                    'human resources manager',\n",
        "                    'human resources specialist',\n",
        "                    'human resources coordinator',\n",
        "                    'hr specialist',\n",
        "                    'hr coordinator',\n",
        "                    'hr generalist'\n",
        "                ],\n",
        "                'senior_hr': [\n",
        "                    'director human resources',\n",
        "                    'senior human resources',\n",
        "                    'chief human resources',\n",
        "                    'hr director',\n",
        "                    'chro',\n",
        "                    'vp hr'\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            # Process and standardize titles\n",
        "            processed_titles = titles.apply(\n",
        "                lambda x: self._process_title_for_clustering(x, important_terms)\n",
        "            )\n",
        "\n",
        "            # Create TF-IDF matrix\n",
        "            self.tfidf_matrix = self.vectorizer.fit_transform(processed_titles)\n",
        "\n",
        "            # Perform clustering and store centroids\n",
        "            clusters = self.kmeans.fit_predict(self.tfidf_matrix)\n",
        "            self.cluster_centroids = self.kmeans.cluster_centers_\n",
        "\n",
        "            return clusters\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Clustering error: {str(e)}\")\n",
        "            return np.zeros(len(titles))\n",
        "\n",
        "    def _process_title_for_clustering(self, title: str, important_terms: Dict) -> str:\n",
        "        \"\"\"\n",
        "    Processes and standardizes job titles for clustering.\n",
        "\n",
        "    Args:\n",
        "        title (str): Raw job title\n",
        "        important_terms (Dict): Dictionary of role terms by category\n",
        "\n",
        "    Returns:\n",
        "        str: Processed title with weighted terms\n",
        "\n",
        "    Example:\n",
        "    >>> terms = {'target_primary': ['aspiring hr']}\n",
        "    >>> processed = clusterer._process_title_for_clustering(\n",
        "    ...     \"Aspiring HR Manager\", terms\n",
        "    ... )\n",
        "    >>> print(processed)\n",
        "    'aspiring hr professional aspiring hr professional aspiring hr professional aspiring hr professional'\n",
        "\n",
        "    Processing Rules:\n",
        "    1. Aspiring HR roles: Weighted 4x\n",
        "    2. Seeking HR roles: Weighted 4x\n",
        "    3. Senior roles: Weighted 3x\n",
        "    4. Manager/Specialist roles: Weighted 2x\n",
        "    5. Non-HR roles: Single category label\n",
        "    \"\"\"\n",
        "\n",
        "        title = title.lower()\n",
        "        processed_parts = []\n",
        "\n",
        "        # Process by role category\n",
        "        if 'aspiring human resources' in title:\n",
        "            processed_parts.extend(['aspiring hr professional'] * 4)  # Higher weight\n",
        "        elif 'seeking human resources' in title:\n",
        "            processed_parts.extend(['seeking hr position'] * 4)\n",
        "        elif any(x in title for x in ['chief', 'director', 'senior vice president']):\n",
        "            processed_parts.extend(['senior hr executive'] * 3)\n",
        "        elif any(x in title for x in ['manager', 'specialist', 'generalist']):\n",
        "            role = next(x for x in ['manager', 'specialist', 'generalist'] if x in title)\n",
        "            processed_parts.extend([f'hr {role}'] * 2)\n",
        "        elif 'coordinator' in title:\n",
        "            processed_parts.extend(['hr coordinator'] * 2)\n",
        "        # Non-HR categorization\n",
        "        elif any(x in title for x in ['teacher', 'education']):\n",
        "            processed_parts.append('education role')\n",
        "        elif any(x in title for x in ['engineer', 'programmer', 'systems']):\n",
        "            processed_parts.append('technical role')\n",
        "        elif 'student' in title:\n",
        "            processed_parts.append('student')\n",
        "        elif any(x in title for x in ['research', 'lab']):\n",
        "            processed_parts.append('research role')\n",
        "        elif 'business' in title:\n",
        "            processed_parts.append('business role')\n",
        "        else:\n",
        "            processed_parts.append('other role')\n",
        "\n",
        "        return ' '.join(processed_parts)\n",
        "\n",
        "    def get_cluster_similarity(self, title: str, cluster_id: int) -> float:\n",
        "        \"\"\"\n",
        "    Calculates cosine similarity between a title and cluster centroid.\n",
        "\n",
        "    Args:\n",
        "        title (str): Job title to compare\n",
        "        cluster_id (int): ID of cluster to compare against\n",
        "\n",
        "    Returns:\n",
        "        float: Similarity score 0-1\n",
        "\n",
        "    Example:\n",
        "    >>> score = clusterer.get_cluster_similarity(\"HR Manager\", 0)\n",
        "    >>> print(f\"{score:.2f}\")  # 0.85 - High similarity to HR cluster\n",
        "\n",
        "    Process:\n",
        "    1. Converts title to TF-IDF vector\n",
        "    2. Gets cluster centroid vector\n",
        "    3. Calculates cosine similarity\n",
        "    4. Returns normalized score (0-1)\n",
        "    \"\"\"\n",
        "\n",
        "        try:\n",
        "            if self.cluster_centroids is None:\n",
        "                return 0.0\n",
        "\n",
        "            # Convert title to vector and calculate similarity\n",
        "            title_vec = self.vectorizer.transform([title])\n",
        "            centroid = self.cluster_centroids[cluster_id].reshape(1, -1)\n",
        "            return float(cosine_similarity(title_vec, centroid)[0][0])\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Similarity calculation error: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "\n",
        "\n",
        "class RankingAgent:\n",
        "    \"\"\"\n",
        "    Agent that evaluates candidates based on title, location, and network criteria.\n",
        "\n",
        "    Features:\n",
        "    - Title-based scoring\n",
        "    - Location tier evaluation\n",
        "    - Professional network scoring\n",
        "    - Adaptive weights based on performance\n",
        "\n",
        "    Example:\n",
        "    agent = RankingAgent('title', processor, weight=1.0)\n",
        "    score = agent.evaluate(candidate)\n",
        "    \"\"\"\n",
        "    def __init__(self, expertise: str, processor, weight: float = 1.0):\n",
        "        self.expertise = expertise        # Scoring criteria (title/location/connections)\n",
        "        self.weight = weight             # Agent's importance weight\n",
        "        self.initial_weight = weight     # Store initial weight\n",
        "        self.performance_history = deque(maxlen=100)  # Track recent performance\n",
        "        self.processor = processor       # Reference to main processor\n",
        "        self.project_keywords = processor.project_keywords  # Keywords for matching\n",
        "\n",
        "    def evaluate(self, candidate: pd.Series) -> float:\n",
        "        \"\"\"\n",
        "\n",
        "        Evaluates candidate based on agent's expertise.\n",
        "\n",
        "        Example:\n",
        "        >>> title_agent = RankingAgent('title', processor)\n",
        "        >>> location_agent = RankingAgent('location', processor)\n",
        "        >>> scores = [\n",
        "        ...     title_agent.evaluate(candidate),     # 0.90\n",
        "        ...     location_agent.evaluate(candidate)   # 0.70\n",
        "        ... ]\n",
        "\n",
        "        Returns score between 0-1.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            if self.expertise == 'title':\n",
        "                return self._title_score(candidate)\n",
        "            elif self.expertise == 'location':\n",
        "                return self._location_score(candidate)\n",
        "            elif self.expertise == 'connections':\n",
        "                return self._connection_score(candidate)\n",
        "            return 0.0\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Agent evaluation error: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def _title_score(self, candidate) -> float:\n",
        "        \"\"\"\n",
        "        Calculates job title relevance score.\n",
        "\n",
        "        Example:\n",
        "        >>> score = agent._title_score({\n",
        "        ...     'cleaned_title': 'aspiring human resources manager'\n",
        "        ... })\n",
        "        >>> print(f\"{score:.2f}\")  # 0.95 - High relevance title\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            title = candidate.get('cleaned_title', '').lower()\n",
        "            return self.processor.get_base_score(title)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Title scoring error: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def _location_score(self, candidate) -> float:\n",
        "        \"\"\"\n",
        "        Scores location based on tech hub tiers.\n",
        "\n",
        "        Returns:\n",
        "        - 1.0: Tier 1 (Texas, California, New York)\n",
        "        - 0.7: Tier 2 (Illinois, Massachusetts, NC)\n",
        "        - 0.6: Focus areas (Canada, Turkey)\n",
        "        - 0.3: Other locations\n",
        "\n",
        "        Example:\n",
        "        >>> score = agent._location_score({\n",
        "        ...     'cleaned_location': 'texas'\n",
        "        ... })\n",
        "        >>> print(f\"{score:.1f}\")  # 1.0 - Tier 1 hub\n",
        "        \"\"\"\n",
        "\n",
        "        location = candidate.get('cleaned_location', 'unknown').lower()\n",
        "        if location in self.processor.tech_hubs['tier1']:\n",
        "            return 1.0  # Top tech hubs\n",
        "        elif location in self.processor.tech_hubs['tier2']:\n",
        "            return 0.7  # Secondary tech hubs\n",
        "        elif location in {'canada', 'turkey'}:\n",
        "            return 0.6  # International focus areas\n",
        "        return 0.3     # Other locations\n",
        "\n",
        "    def _connection_score(self, candidate) -> float:\n",
        "        \"\"\"\n",
        "        Score professional network size (0-1)\n",
        "        Normalized to max of 500 connections\n",
        "        \"\"\"\n",
        "        connections = candidate.get('cleaned_connections', 0)\n",
        "        return min(connections / 500.0, 1.0)\n",
        "\n",
        "    def update_weight(self, success_rate: float):\n",
        "        \"\"\"\n",
        "\n",
        "        Adjusts agent weight based on performance.\n",
        "\n",
        "        Example:\n",
        "        >>> agent = RankingAgent('title', processor, weight=0.5)\n",
        "        >>> agent.update_weight(0.8)  # Good performance\n",
        "        >>> print(f\"{agent.weight:.2f}\")  # 0.53 - Weight increased\n",
        "        >>> agent.update_weight(0.3)  # Poor performance\n",
        "        >>> print(f\"{agent.weight:.2f}\")  # 0.48 - Weight decreased\n",
        "        Weight increases/decreases by up to 10% based on success.\n",
        "        \"\"\"\n",
        "        self.weight *= 1 + (success_rate - 0.5) * 0.1  # Adjust weight\n",
        "        self.performance_history.append(success_rate)   # Track performance\n",
        "\n",
        "\n",
        "\n",
        "class HRTalentProcessor:\n",
        "    \"\"\"\n",
        "    Main processor for HR talent ranking and evaluation.\n",
        "\n",
        "    Features:\n",
        "    - Title standardization and cleaning\n",
        "    - Location-based scoring\n",
        "    - Professional network evaluation\n",
        "    - Candidate clustering\n",
        "    - Performance metrics tracking\n",
        "\n",
        "    Example:\n",
        "    processor = HRTalentProcessor()\n",
        "    results = processor.process_data(candidates_df)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # Define HR role keywords\n",
        "        self.project_keywords = {\n",
        "            'primary': {\n",
        "                'aspiring': ['aspiring human resources'],\n",
        "                'seeking': ['seeking human resources']\n",
        "            },\n",
        "            'variations': {\n",
        "                'aspiring': [\n",
        "                    'aspiring human resources professional',\n",
        "                    'aspiring human resources specialist',\n",
        "                    'aspiring human resources generalist',\n",
        "                    'aspiring human resources manager',\n",
        "                    'aspiring human resources analyst',\n",
        "                    'aspiring hr professional'\n",
        "                ],\n",
        "                'seeking': [\n",
        "                    'seeking human resources position',\n",
        "                    'seeking human resources opportunities',\n",
        "                    'seeking human resources hris',\n",
        "                    'seeking hr position',\n",
        "                    'seeking hr opportunities',\n",
        "                    'seeking human resource'\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Define location tiers\n",
        "        self.tech_hubs = {\n",
        "            'tier1': {'texas', 'california', 'new york'},\n",
        "            'tier2': {'illinois', 'massachusetts', 'north carolina'}\n",
        "        }\n",
        "\n",
        "        # Initialize metrics tracking\n",
        "        self.metrics = {\n",
        "            'total_candidates': 0,\n",
        "            'hr_candidates': 0,\n",
        "            'role_categories': {\n",
        "                'aspiring_hr': 0,\n",
        "                'seeking_hr': 0,\n",
        "                'senior_hr': 0,\n",
        "                'mid_level_hr': 0,\n",
        "                'junior_hr': 0,\n",
        "                'hr_adjacent': 0,\n",
        "                'other_roles': 0\n",
        "            },\n",
        "            'keyword_matches': {\n",
        "                'aspiring': 0,\n",
        "                'seeking': 0,\n",
        "                'other_hr': 0\n",
        "            },\n",
        "            'starred_profiles': [],\n",
        "            'performance_metrics': {\n",
        "                'initial_cutoff': 0.0,\n",
        "                'final_cutoff': 0.0,\n",
        "                'agent_adaptations': 0,\n",
        "                'ranking_changes': 0,\n",
        "                'genetic_optimizations': 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Initialize components\n",
        "        self.clusterer = TalentClusterer(n_clusters=5)\n",
        "        self.agents = self._initialize_agents()\n",
        "        self.tie_breaker = GeneticTieBreaker()\n",
        "\n",
        "        # Track history\n",
        "        self.final_scores = []\n",
        "        self.weight_history = []\n",
        "        self.cluster_sizes = {}\n",
        "        self.category_distribution = {}\n",
        "\n",
        "    def _initialize_agents(self) -> List[RankingAgent]:\n",
        "        \"\"\"\n",
        "        Creates weighted ranking agents for different evaluation criteria.\n",
        "\n",
        "        Weights Distribution:\n",
        "        - Title (90%): 3 agents × 30%\n",
        "        - Location (5%): 2 agents × 2.5%\n",
        "        - Network (5%): 2 agents × 2.5%\n",
        "\n",
        "        Example:\n",
        "        >>> agents = processor._initialize_agents()\n",
        "        >>> len(agents)  # 7 total agents\n",
        "        >>> [agent.weight for agent in agents]  # [0.3, 0.3, 0.3, 0.025, 0.025, 0.025, 0.025]\n",
        "        \"\"\"\n",
        "\n",
        "        agents = []\n",
        "        # Title agents\n",
        "        for _ in range(3):\n",
        "            agents.append(RankingAgent('title', self, weight=0.3))\n",
        "        # Location agents\n",
        "        for _ in range(2):\n",
        "            agents.append(RankingAgent('location', self, weight=0.025))\n",
        "        # Connection agents\n",
        "        for _ in range(2):\n",
        "            agents.append(RankingAgent('connections', self, weight=0.025))\n",
        "        return agents\n",
        "\n",
        "    def clean_title(self, title: str) -> str:\n",
        "        \"\"\"\n",
        "        Standardizes job titles into categories.\n",
        "\n",
        "        Example:\n",
        "        >>> processor = HRTalentProcessor()\n",
        "        >>> processor.clean_title('HR Manager')\n",
        "        'human resources manager'\n",
        "        >>> processor.clean_title('Teacher')\n",
        "        'NON-HR: Education'\n",
        "\n",
        "        Categories:\n",
        "        1. Aspiring HR:\n",
        "           - professional, specialist, generalist, manager\n",
        "        2. Seeking HR:\n",
        "           - position, opportunities, HRIS\n",
        "        3. Senior HR:\n",
        "           - CHRO, director, SVP\n",
        "        4. Standard HR:\n",
        "           - specialist, generalist, coordinator, manager\n",
        "        5. Non-HR:\n",
        "           - Education, Technical, Student, Management, Research, Business\n",
        "        \"\"\"\n",
        "\n",
        "        if not isinstance(title, str):\n",
        "            return \"NON-HR: Invalid Title\"\n",
        "\n",
        "        title = title.lower().strip()\n",
        "\n",
        "        # Process by category\n",
        "        # Aspiring HR roles\n",
        "        if 'aspiring human resources' in title:\n",
        "            if 'professional' in title:\n",
        "                return 'aspiring human resources professional'\n",
        "            elif 'specialist' in title:\n",
        "                return 'aspiring human resources specialist'\n",
        "            elif 'generalist' in title:\n",
        "                return 'aspiring human resources generalist'\n",
        "            elif 'manager' in title:\n",
        "                return 'aspiring human resources manager'\n",
        "            return 'aspiring human resources professional'\n",
        "\n",
        "        # Seeking HR roles\n",
        "        if 'seeking human resources' in title:\n",
        "            if 'hris' in title:\n",
        "                return 'seeking human resources hris position'\n",
        "            elif 'position' in title:\n",
        "                return 'seeking human resources position'\n",
        "            return 'seeking human resources opportunities'\n",
        "\n",
        "        # Senior HR roles\n",
        "        if 'chro' in title or ('svp' in title and 'hr' in title):\n",
        "            return 'chief human resources officer'\n",
        "        if 'director' in title and 'human resources' in title:\n",
        "            return 'director human resources'\n",
        "\n",
        "        # HR roles\n",
        "        if any(x in title for x in ['human resources', 'hr']):\n",
        "            if 'senior' in title or 'sr' in title:\n",
        "                return 'senior human resources specialist'\n",
        "            elif 'specialist' in title:\n",
        "                return 'human resources specialist'\n",
        "            elif 'generalist' in title:\n",
        "                return 'human resources generalist'\n",
        "            elif 'coordinator' in title:\n",
        "                return 'human resources coordinator'\n",
        "            elif 'manager' in title:\n",
        "                return 'human resources manager'\n",
        "            return 'human resources professional'\n",
        "\n",
        "        # Adjacent roles\n",
        "        if 'people development' in title:\n",
        "            return 'people development coordinator'\n",
        "\n",
        "        # Non-HR categorization\n",
        "        if 'teacher' in title or 'education' in title:\n",
        "            return 'NON-HR: Education'\n",
        "        if any(x in title for x in ['engineer', 'programmer', 'systems']):\n",
        "            return 'NON-HR: Technical'\n",
        "        if 'student' in title and not any(x in title for x in ['hr', 'human resources']):\n",
        "            return 'NON-HR: Student'\n",
        "        if 'director' in title or 'administration' in title:\n",
        "            return 'NON-HR: Management'\n",
        "        if 'research' in title or 'lab' in title:\n",
        "            return 'NON-HR: Research'\n",
        "        if 'business' in title and not any(x in title for x in ['hr', 'human resources']):\n",
        "            return 'NON-HR: Business'\n",
        "\n",
        "        return 'NON-HR: Other'\n",
        "\n",
        "    def clean_location(self, location: str) -> str:\n",
        "        \"\"\"\n",
        "        Clean and standardize location names.\n",
        "        Maps cities to states and handles international locations.\n",
        "\n",
        "        Example:\n",
        "        'New York City' -> 'new york'\n",
        "        'İzmir' -> 'turkey'\n",
        "        \"\"\"\n",
        "        if not isinstance(location, str):\n",
        "            return \"unknown\"\n",
        "\n",
        "        # Clean and normalize\n",
        "        location = location.lower().strip()\n",
        "        location = (location.encode('utf-8', 'ignore')\n",
        "                          .decode('utf-8')\n",
        "                          .lower()\n",
        "                          .strip())\n",
        "\n",
        "        # Location mappings\n",
        "        metro_to_state = {\n",
        "            'grand rapids': 'michigan',\n",
        "            'san francisco bay': 'california',\n",
        "            'houston': 'texas',\n",
        "            'dallas': 'texas',\n",
        "            'austin': 'texas',\n",
        "            'new york city': 'new york',\n",
        "            'boston': 'massachusetts',\n",
        "            'chicago': 'illinois',\n",
        "            'chattanooga': 'tennessee',\n",
        "            'virginia beach': 'virginia'\n",
        "        }\n",
        "\n",
        "        international_mapping = {\n",
        "            'kanada': 'canada',\n",
        "            'ä°zmir': 'turkey',\n",
        "            'izmir': 'turkey',\n",
        "            'tã¼rkiye': 'turkey',\n",
        "            'türkiye': 'turkey',\n",
        "            'amerika birleåÿik devletleri': 'united states',\n",
        "            'amerika birleşik devletleri': 'united states'\n",
        "        }\n",
        "\n",
        "        # Check international names\n",
        "        for old, new in international_mapping.items():\n",
        "            if old in location:\n",
        "                return new\n",
        "\n",
        "        # Clean location text\n",
        "        location = re.sub(r'\\b(greater|area|metropolitan)\\b', '', location)\n",
        "\n",
        "        # Process city,state format\n",
        "        if ',' in location:\n",
        "            parts = [part.strip() for part in location.split(',')]\n",
        "            city = parts[0]\n",
        "            if city in metro_to_state:\n",
        "                return metro_to_state[city]\n",
        "            if len(parts) > 1:\n",
        "                state = parts[1].strip()\n",
        "                state = re.sub(r'\\s+area$', '', state)\n",
        "                if state in self.tech_hubs['tier1'] or state in self.tech_hubs['tier2']:\n",
        "                    return state\n",
        "            return city\n",
        "\n",
        "        # Check metro areas\n",
        "        for metro, state in metro_to_state.items():\n",
        "            if metro in location:\n",
        "                return state\n",
        "\n",
        "        return location\n",
        "\n",
        "    def clean_connections(self, connections) -> int:\n",
        "        \"\"\"\n",
        "        Clean and normalize connection counts.\n",
        "        Handles string formatting and caps at 500.\n",
        "\n",
        "        Example:\n",
        "        '500+' -> 500\n",
        "        '250' -> 250\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if isinstance(connections, str):\n",
        "                connections = connections.replace('+', '').strip()\n",
        "            return min(int(connections), 500)\n",
        "        except (ValueError, TypeError):\n",
        "            return 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # Scoring and normalization methods for HR talent processor\n",
        "\n",
        "    def calculate_agent_consensus(self, candidate: pd.Series) -> float:\n",
        "        \"\"\"\n",
        "    Calculates the weighted average score from multiple ranking agents.\n",
        "\n",
        "    Args:\n",
        "        candidate (pd.Series): Candidate information containing title, location, connections\n",
        "\n",
        "    Returns:\n",
        "        float: Combined weighted score between 0-1\n",
        "\n",
        "    Example:\n",
        "    >>> # Initialize agents with different weights\n",
        "    >>> agents = [\n",
        "    ...     RankingAgent('title', weight=0.6),      # Title is 60% of score\n",
        "    ...     RankingAgent('location', weight=0.3),    # Location is 30% of score\n",
        "    ...     RankingAgent('connections', weight=0.1)  # Connections is 10% of score\n",
        "    ... ]\n",
        "    >>>\n",
        "    >>> # Example candidate\n",
        "    >>> candidate = pd.Series({\n",
        "    ...     'cleaned_title': 'HR Manager',          # Title score: 0.65\n",
        "    ...     'cleaned_location': 'new york',         # Location score: 1.0 (Tier 1)\n",
        "    ...     'cleaned_connections': 400              # Connection score: 0.8 (400/500)\n",
        "    ... })\n",
        "    >>>\n",
        "    >>> # Calculate weighted scores\n",
        "    >>> scores = [\n",
        "    ...     0.65 * 0.6,  # Title: 0.39\n",
        "    ...     1.0 * 0.3,   # Location: 0.30\n",
        "    ...     0.8 * 0.1    # Connections: 0.08\n",
        "    ... ]\n",
        "    >>>\n",
        "    >>> # Final consensus score\n",
        "    >>> final_score = sum(scores)  # 0.39 + 0.30 + 0.08 = 0.77\n",
        "\n",
        "    Calculation Process:\n",
        "    1. Each agent evaluates candidate in their domain:\n",
        "       - Title agent looks at role relevance\n",
        "       - Location agent checks tech hub tier\n",
        "       - Connection agent normalizes network size\n",
        "\n",
        "    2. Each score is multiplied by agent weight:\n",
        "       - Title might be 60% of final score\n",
        "       - Location might be 30%\n",
        "       - Connections might be 10%\n",
        "\n",
        "    3. Weighted scores are summed for final consensus\n",
        "\n",
        "    Note: Weights should sum to 1.0 for proper normalization\n",
        "    \"\"\"\n",
        "        try:\n",
        "            scores = [agent.evaluate(candidate) * agent.weight\n",
        "                      for agent in self.agents]\n",
        "            return sum(scores)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Consensus calculation error: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def get_base_score(self, title: str) -> float:\n",
        "        \"\"\"\n",
        "    Calculates base score from job title.\n",
        "\n",
        "    Score ranges:\n",
        "    - 0.90-1.00: Aspiring/seeking HR roles\n",
        "    - 0.70-0.89: Senior HR roles (CHRO, Director)\n",
        "    - 0.50-0.69: Standard HR roles\n",
        "    - 0.30-0.49: HR-adjacent roles\n",
        "    - 0.05: Non-HR roles\n",
        "\n",
        "    Example:\n",
        "    >>> processor.get_base_score('aspiring hr professional')\n",
        "    0.95\n",
        "    >>> processor.get_base_score('hr manager')\n",
        "    0.65\n",
        "    \"\"\"\n",
        "        if not isinstance(title, str) or not title:\n",
        "            return 0.05\n",
        "\n",
        "        # Score tiers\n",
        "        if any(x in title.lower() for x in ['aspiring human resources', 'seeking human resources']):\n",
        "            if 'professional' in title or 'specialist' in title:\n",
        "                return 0.95\n",
        "            if 'generalist' in title or 'manager' in title:\n",
        "                return 0.92\n",
        "            return 0.90\n",
        "\n",
        "        if 'chief human resources officer' in title or 'chro' in title:\n",
        "            return 0.85\n",
        "        if 'director human resources' in title:\n",
        "            return 0.82\n",
        "        if 'senior human resources' in title:\n",
        "            return 0.78\n",
        "\n",
        "        if 'human resources manager' in title:\n",
        "            return 0.65\n",
        "        if 'human resources specialist' in title:\n",
        "            return 0.62\n",
        "        if 'human resources generalist' in title:\n",
        "            return 0.60\n",
        "        if 'human resources coordinator' in title:\n",
        "            return 0.55\n",
        "        if 'human resources professional' in title:\n",
        "            return 0.52\n",
        "\n",
        "        if 'people development' in title:\n",
        "            return 0.45\n",
        "\n",
        "        if title.startswith('NON-HR:'):\n",
        "            return 0.05\n",
        "\n",
        "        return 0.05\n",
        "\n",
        "    def normalize_scores(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "    Normalizes candidate scores to 0-1 range.\n",
        "\n",
        "    Example:\n",
        "    >>> df = pd.DataFrame({'cleaned_title': ['HR Manager', 'Teacher']})\n",
        "    >>> normalized = processor.normalize_scores(df)\n",
        "    >>> print(normalized['final_score'])\n",
        "    0    0.65  # HR Manager\n",
        "    1    0.05  # Teacher\n",
        "    \"\"\"\n",
        "\n",
        "        try:\n",
        "            if df is None or df.empty:\n",
        "                return df\n",
        "\n",
        "            result_df = df.copy()\n",
        "            result_df['base_score'] = result_df['cleaned_title'].apply(self.get_base_score)\n",
        "            result_df['final_score'] = result_df['base_score']\n",
        "            result_df['final_score'] = result_df['final_score'].clip(0, 1)\n",
        "\n",
        "            return result_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in normalize_scores: {str(e)}\")\n",
        "            return df\n",
        "\n",
        "    def prevent_bias(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "    Prevents scoring bias through cluster normalization.\n",
        "\n",
        "    Process:\n",
        "    1. Normalizes scores within clusters (z-score)\n",
        "    2. Applies diversity factor (10% adjustment)\n",
        "    3. Adjusts for keyword representation (10% adjustment)\n",
        "    4. Clips final scores to 0-1 range\n",
        "\n",
        "    Example:\n",
        "    >>> df['cluster'] = [0, 0, 1]  # Two clusters\n",
        "    >>> unbiased = processor.prevent_bias(df)\n",
        "    \"\"\"\n",
        "\n",
        "        try:\n",
        "            if 'cluster' not in df.columns:\n",
        "                return df\n",
        "\n",
        "            # Normalize cluster scores\n",
        "            df['cluster_normalized_score'] = df.groupby('cluster')['final_score'].transform(\n",
        "                lambda x: (x - x.mean()) / (x.std() if x.std() != 0 else 1)\n",
        "            )\n",
        "\n",
        "            # Calculate diversity metrics\n",
        "            cluster_sizes = df.groupby('cluster').size()\n",
        "            total_candidates = len(df)\n",
        "            diversity_factor = 1 - (cluster_sizes / total_candidates)\n",
        "\n",
        "            # Get keyword metrics\n",
        "            cluster_keyword_ratio = df.groupby('cluster').apply(\n",
        "                lambda g: sum(1 for title in g['cleaned_title']\n",
        "                              if any(kw in title.lower()\n",
        "                                    for kw in self.project_keywords['primary'])) / len(g),\n",
        "                include_groups=False\n",
        "            )\n",
        "\n",
        "            # Apply adjustments\n",
        "            for cluster in df['cluster'].unique():\n",
        "                mask = df['cluster'] == cluster\n",
        "                diversity_adjustment = diversity_factor[cluster] * 0.1\n",
        "                keyword_adjustment = cluster_keyword_ratio[cluster] * 0.1\n",
        "\n",
        "                df.loc[mask, 'final_score'] = df.loc[mask, 'final_score'].apply(\n",
        "                    lambda x: x * (1 + diversity_adjustment + keyword_adjustment)\n",
        "                )\n",
        "\n",
        "            df['final_score'] = df['final_score'].clip(0, 1)\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in bias prevention: {str(e)}\")\n",
        "            return df\n",
        "\n",
        "    def display_results(self, df: pd.DataFrame):\n",
        "        \"\"\"Display analysis results in GitHub-friendly markdown format\"\"\"\n",
        "        print(\"\\n# HR TALENT RANKING ANALYSIS\")\n",
        "        print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "        # Distribution summary with markdown table\n",
        "        total = len(df)\n",
        "        distribution_data = [\n",
        "            ['Target Roles (≥0.90)', len(df[df['final_score'] >= 0.9]), f\"{len(df[df['final_score'] >= 0.9])/total*100:.3f}\"],\n",
        "            ['Senior HR (0.40-0.89)', len(df[(df['final_score'] >= 0.4) & (df['final_score'] < 0.9)]), f\"{len(df[(df['final_score'] >= 0.4) & (df['final_score'] < 0.9)])/total*100:.3f}\"],\n",
        "            ['Other Roles (<0.40)', len(df[df['final_score'] < 0.4]), f\"{len(df[df['final_score'] < 0.4])/total*100:.3f}\"]\n",
        "        ]\n",
        "\n",
        "        print(\"## CANDIDATE DISTRIBUTION\\n\")\n",
        "        print(\"| Category | Count | Percentage |\")\n",
        "        print(\"|----------|--------|------------|\")\n",
        "        for row in distribution_data:\n",
        "            print(f\"| {row[0]} | {row[1]} | {row[2]} |\")\n",
        "\n",
        "        # Score guide with markdown table\n",
        "        print(\"\\n## SCORE GUIDE\\n\")\n",
        "        print(\"| Priority | Range | Category |\")\n",
        "        print(\"|----------|--------|----------|\")\n",
        "        print(\"| High | 0.90 - 1.00 | Primary Target |\")\n",
        "        print(\"| High | 0.40 - 0.89 | Senior HR |\")\n",
        "        print(\"| Low | 0.05 - 0.39 | Other/Non-HR |\")\n",
        "\n",
        "        def is_senior_role(title):\n",
        "            \"\"\"Determines if a role is actually senior (not aspiring/seeking)\"\"\"\n",
        "            senior_keywords = ['SVP', 'CHRO', 'Chief', 'Director', 'Senior VP', 'Vice President', 'Senior', 'Manager']\n",
        "            target_keywords = ['aspiring', 'seeking', 'entry-level', 'entry level', 'internship']\n",
        "\n",
        "            if any(keyword.lower() in title.lower() for keyword in target_keywords):\n",
        "                return False\n",
        "            return any(keyword.lower() in title.lower() for keyword in senior_keywords)\n",
        "\n",
        "        def is_target_role(title):\n",
        "            \"\"\"Determines if a role is a target role (aspiring/seeking)\"\"\"\n",
        "            target_keywords = ['aspiring', 'seeking', 'entry-level', 'entry level', 'internship']\n",
        "            return any(keyword.lower() in title.lower() for keyword in target_keywords)\n",
        "\n",
        "        # Display candidates by score range\n",
        "        def display_candidate_group(candidates, title):\n",
        "            if candidates.empty:\n",
        "                return\n",
        "\n",
        "            filtered_candidates = candidates.copy()\n",
        "\n",
        "            # Apply proper filtering\n",
        "            if \"PRIMARY TARGET\" in title:\n",
        "                filtered_candidates = filtered_candidates[\n",
        "                    filtered_candidates['job_title'].apply(is_target_role) &\n",
        "                    ~filtered_candidates['job_title'].apply(is_senior_role)\n",
        "                ]\n",
        "            elif \"SENIOR HR PROFESSIONALS\" in title:\n",
        "                filtered_candidates = filtered_candidates[\n",
        "                    ((filtered_candidates['job_title'].apply(is_senior_role)) |\n",
        "                    (filtered_candidates['cleaned_title'].str.contains('senior|manager|specialist', case=False, na=False))) &\n",
        "                    ~filtered_candidates['job_title'].str.contains('aspiring|seeking', case=False, na=False)\n",
        "                ]\n",
        "\n",
        "            if filtered_candidates.empty:\n",
        "                return\n",
        "\n",
        "            print(f\"\\n## {title}\\n\")\n",
        "            display_cols = ['id', 'job_title', 'cleaned_title', 'cleaned_location',\n",
        "                          'cleaned_connections', 'final_score']\n",
        "\n",
        "            # Print table header\n",
        "            headers = ['ID', 'Job Title', 'Cleaned Title', 'Location', 'Connections', 'Score']\n",
        "            print(\"| \" + \" | \".join(headers) + \" |\")\n",
        "            print(\"|-\" + \"-|-\".join(\"-\" * len(h) for h in headers) + \"-|\")\n",
        "\n",
        "            # Print rows\n",
        "            for _, row in filtered_candidates.head(10).iterrows():\n",
        "                print(f\"| {row['id']} | {row['job_title']} | {row['cleaned_title']} | {row['cleaned_location']} | {row['cleaned_connections']} | {row['final_score']:.3f} |\")\n",
        "\n",
        "        # Display each group\n",
        "        display_candidate_group(\n",
        "            df[df['final_score'] >= 0.9],\n",
        "            \"TOP 10 PRIMARY TARGET CANDIDATES (Score ≥ 0.90)\"\n",
        "        )\n",
        "\n",
        "        display_candidate_group(\n",
        "            df[(df['final_score'] >= 0.4) & (df['final_score'] < 0.9)],\n",
        "            \"TOP 10 SENIOR HR PROFESSIONALS (Score 0.40-0.89)\"\n",
        "        )\n",
        "\n",
        "        display_candidate_group(\n",
        "            df[df['final_score'] < 0.4],\n",
        "            \"TOP 10 OTHER ROLES (Score < 0.40)\"\n",
        "        )\n",
        "\n",
        "    def _display_candidate_section(self, candidates: pd.DataFrame, title: str):\n",
        "        \"\"\"\n",
        "        Display formatted candidate details grouped by category.\n",
        "        Shows rank, ID, title, role, location, network and score.\n",
        "        \"\"\"\n",
        "        if candidates.empty:\n",
        "            return\n",
        "\n",
        "        print(f\"\\n{title}\")\n",
        "        print(\"-\"*100)\n",
        "\n",
        "        for idx, (_, candidate) in enumerate(candidates.iterrows(), 1):\n",
        "            print(f\"\\nRank #{idx}\")\n",
        "            print(f\"Candidate ID: {candidate['id']}\")\n",
        "            print(f\"Title: {candidate['job_title']}\")\n",
        "            print(f\"Role/Category: {candidate['cleaned_title']}\")\n",
        "            print(f\"Location: {candidate['cleaned_location']}\")\n",
        "            print(f\"Network: {candidate['cleaned_connections']} connections\")\n",
        "            print(f\"Score: {candidate['final_score']:.3f}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "    def _display_cluster_analysis(self, df: pd.DataFrame):\n",
        "        \"\"\"\n",
        "        Display cluster statistics and composition analysis.\n",
        "        Shows metrics like average scores, sizes, keyword matches.\n",
        "        \"\"\"\n",
        "        print(\"\\nCANDIDATE CLUSTER ANALYSIS\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Calculate cluster stats\n",
        "        cluster_stats = df.groupby('cluster').agg({\n",
        "            'final_score': ['mean', 'count'],\n",
        "            'cleaned_title': lambda x: sum(1 for title in x if any(\n",
        "                kw in title.lower() for kw in self.project_keywords['primary']\n",
        "            ))\n",
        "        }).round(4)\n",
        "\n",
        "        cluster_stats.columns = ['Average Score', 'Group Size', 'Keyword Matches']\n",
        "        print(\"\\nCluster Performance Metrics:\")\n",
        "        print(cluster_stats)\n",
        "\n",
        "        # Show cluster compositions\n",
        "        print(\"\\nCluster Composition Analysis:\")\n",
        "        for cluster in df['cluster'].unique():\n",
        "            cluster_df = df[df['cluster'] == cluster]\n",
        "            print(f\"\\nCluster {cluster} Profile:\")\n",
        "            print(f\"Total Members: {len(cluster_df)}\")\n",
        "            if len(cluster_df) > 0:\n",
        "                print(\"Representative Titles:\")\n",
        "                for title in cluster_df['cleaned_title'].head(3):\n",
        "                    print(f\"- {title}\")\n",
        "\n",
        "\n",
        "    def display_project_challenges(self, df: pd.DataFrame):\n",
        "        \"\"\"\n",
        "        Display key metrics and analysis results:\n",
        "        - Algorithm effectiveness\n",
        "        - Candidate distribution\n",
        "        - Quality thresholds\n",
        "        - Bias prevention measures\n",
        "        \"\"\"\n",
        "        print(\"\\n ANALYSIS OF PROJECT CHALLENGES\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        # Calculate metrics\n",
        "        target_score = 0.90\n",
        "        high_potential = len(df[df['final_score'] >= target_score])\n",
        "        qualified_hr = len(df[(df['final_score'] >= 0.40) &\n",
        "                            (df['final_score'] < target_score)])\n",
        "        non_hr = len(df[df['final_score'] < 0.40])\n",
        "\n",
        "        # Show algorithm performance\n",
        "        print(\"\\n1. Algorithm Performance & Effectiveness\")\n",
        "        print(\"-\"*50)\n",
        "        print(\"Our scoring system combines multiple factors with weighted importance:\")\n",
        "        print(\"• Job Title Analysis (90% of total score)\")\n",
        "        print(\"  - Identifies aspiring and seeking HR professionals\")\n",
        "        print(\"  - Evaluates current HR role levels\")\n",
        "        print(\"• Location Impact (5% of total score)\")\n",
        "        print(\"  - Considers tech hubs and major markets\")\n",
        "        print(\"• Professional Network (5% of total score)\")\n",
        "        print(\"  - Measures industry connections\")\n",
        "\n",
        "        # Show candidate distribution\n",
        "        print(\"\\n2. Candidate Pool Analysis\")\n",
        "        print(\"-\"*50)\n",
        "        print(f\"From {len(df)} total candidates:\")\n",
        "        print(f\"• Primary targets: {high_potential} ({high_potential/len(df)*100:.1f}%)\")\n",
        "        print(f\"• Qualified HR professionals: {qualified_hr} ({qualified_hr/len(df)*100:.1f}%)\")\n",
        "        print(f\"• Non-HR profiles: {non_hr} ({non_hr/len(df)*100:.1f}%)\")\n",
        "\n",
        "        # Show quality control\n",
        "        print(\"\\n3. Quality Control & Cutoff Analysis\")\n",
        "        print(\"-\"*50)\n",
        "        print(\"Dynamic scoring thresholds:\")\n",
        "        print(f\"• Target threshold: {target_score:.2f}\")\n",
        "        print(f\"• High-potential candidates: {high_potential} profiles\")\n",
        "        print(\"• Qualified HR threshold: 0.40\")\n",
        "\n",
        "        # Show bias prevention\n",
        "        print(\"\\n4. Bias Prevention & Fair Evaluation\")\n",
        "        print(\"-\"*50)\n",
        "        print(\"Multiple measures ensure unbiased assessment:\")\n",
        "        print(\"• Role-based scoring prioritizes relevant experience\")\n",
        "        print(\"• Location consideration limited to 5% impact\")\n",
        "        print(\"• Network size normalized to prevent seniority bias\")\n",
        "        print(\"• Cluster analysis promotes diverse candidate pool\")\n",
        "\n",
        "\n",
        "    def _get_rank_label(self, score: float) -> str:\n",
        "        if score >= 0.90:\n",
        "            return \"Primary Target\"\n",
        "        elif score >= 0.70:\n",
        "            return \"Strong HR Match\"\n",
        "        elif score >= 0.40:\n",
        "            return \"Senior HR Professional\"\n",
        "        elif score >= 0.25:\n",
        "            return \"Mid-Level/Junior HR\"\n",
        "        elif score >= 0.15:\n",
        "            return \"HR Adjacent\"\n",
        "        else:\n",
        "            return \"Non-HR Role\"\n",
        "\n",
        "\n",
        "    def display_reranking_results(self, original_df: pd.DataFrame, reranked_df: pd.DataFrame):\n",
        "        \"\"\"\n",
        "        Display changes in candidate rankings after reranking:\n",
        "        - Position changes\n",
        "        - Score updates\n",
        "        - Rank label changes\n",
        "        \"\"\"\n",
        "        print(\"\\n RERANKING IMPACT ANALYSIS\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        changes = []\n",
        "        for i in range(min(10, len(original_df))):\n",
        "            old_id = original_df.iloc[i]['id']\n",
        "            new_id = reranked_df.iloc[i]['id']\n",
        "            if old_id != new_id:\n",
        "                old_rank = original_df[original_df['id'] == old_id].index[0] + 1\n",
        "                new_rank = reranked_df[reranked_df['id'] == new_id].index[0] + 1\n",
        "                changes.append({\n",
        "                    'id': new_id,\n",
        "                    'old_rank': old_rank,\n",
        "                    'new_rank': new_rank,\n",
        "                    'title': reranked_df[reranked_df['id'] == new_id]['cleaned_title'].iloc[0],\n",
        "                    'score': reranked_df[reranked_df['id'] == new_id]['final_score'].iloc[0],\n",
        "                    'rank_label': self._get_rank_label(reranked_df[reranked_df['id'] == new_id]['final_score'].iloc[0])\n",
        "                })\n",
        "\n",
        "        if changes:\n",
        "            print(\"\\nSignificant Ranking Changes:\")\n",
        "            print(\"-\"*50)\n",
        "            for change in changes:\n",
        "                print(f\"\\nCandidate ID: {change['id']}\")\n",
        "                print(f\"Previous Rank: #{change['old_rank']}\")\n",
        "                print(f\"New Rank: #{change['new_rank']}\")\n",
        "                print(f\"Role: {change['title']}\")\n",
        "                print(f\"Score: {change['score']:.3f}\")\n",
        "                print(f\"Rank Label: {change['rank_label']}\")\n",
        "\n",
        "            print(f\"\\nTotal Position Changes: {len(changes)}\")\n",
        "            avg_movement = sum(abs(c['new_rank'] - c['old_rank']) for c in changes) / len(changes)\n",
        "            print(f\"Average Rank Movement: {avg_movement:.1f} positions\")\n",
        "        else:\n",
        "            print(\"\\nNo significant changes in rankings\")\n",
        "\n",
        "\n",
        "    def process_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Process candidate data for HR talent ranking.\n",
        "\n",
        "        Steps:\n",
        "        1. Validate input data\n",
        "        2. Clean and standardize fields\n",
        "        3. Calculate scores\n",
        "        4. Apply clustering\n",
        "        5. Prevent bias\n",
        "\n",
        "        Example:\n",
        "        results = processor.process_data(candidates_df)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logger.info(\"Starting data processing pipeline...\")\n",
        "\n",
        "            # Validate DataFrame\n",
        "            if df is None or df.empty:\n",
        "                logger.error(\"Invalid input DataFrame\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            # Create working copy & map columns\n",
        "            processed_df = df.copy()\n",
        "            processed_df = processed_df.rename(columns={\n",
        "                'Job Title': 'job_title',\n",
        "                'Location': 'location',\n",
        "                'Connection': 'connection',\n",
        "                'ID': 'id'\n",
        "            })\n",
        "\n",
        "            # Validate required columns exist\n",
        "            required_columns = {'id', 'job_title', 'location', 'connection'}\n",
        "            if not required_columns.issubset(set(map(str.lower, processed_df.columns))):\n",
        "                logger.error(f\"Missing columns: {required_columns - current_columns}\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            # Convert data types\n",
        "            processed_df['id'] = processed_df['id'].fillna(0).astype(int)\n",
        "            processed_df['job_title'] = processed_df['job_title'].fillna('').astype(str)\n",
        "            processed_df['location'] = processed_df['location'].fillna('').astype(str)\n",
        "            processed_df['connection'] = processed_df['connection'].fillna('0').astype(str)\n",
        "\n",
        "            # Clean and standardize fields\n",
        "            processed_df['cleaned_title'] = processed_df['job_title'].apply(self.clean_title)\n",
        "            processed_df['cleaned_location'] = processed_df['location'].apply(self.clean_location)\n",
        "            processed_df['cleaned_connections'] = processed_df['connection'].apply(self.clean_connections)\n",
        "\n",
        "            # Calculate scores\n",
        "            processed_df['agent_score'] = processed_df.apply(self.calculate_agent_consensus, axis=1)\n",
        "            processed_df['final_score'] = processed_df['agent_score']\n",
        "\n",
        "            # Apply normalization\n",
        "            processed_df = self.normalize_scores(processed_df)\n",
        "\n",
        "            # Apply clustering if enough candidates\n",
        "            if len(processed_df) >= 5:\n",
        "                processed_df['cluster'] = self.clusterer.create_clusters(processed_df['cleaned_title'])\n",
        "                processed_df['cluster_similarity'] = processed_df.apply(\n",
        "                    lambda x: self.clusterer.get_cluster_similarity(\n",
        "                        x['cleaned_title'],\n",
        "                        int(x['cluster'])\n",
        "                    ),\n",
        "                    axis=1\n",
        "                )\n",
        "                processed_df = self.prevent_bias(processed_df)\n",
        "\n",
        "            return processed_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Processing error: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "\n",
        "    def rerank_after_starring(self, df: pd.DataFrame, starred_id) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "    Reranks all candidates based on their similarity to a starred/selected candidate.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Dataframe containing candidate information\n",
        "        starred_id: ID of the selected candidate to compare against\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Reranked dataframe with updated scores\n",
        "\n",
        "    Example:\n",
        "    >>> processor = HRTalentProcessor()\n",
        "    >>> df = pd.DataFrame({\n",
        "    ...     'id': [1, 2, 3],\n",
        "    ...     'cleaned_title': ['HR Manager', 'HR Specialist', 'Sales Manager'],\n",
        "    ...     'cleaned_location': ['Texas', 'Texas', 'California']\n",
        "    ... })\n",
        "    >>> reranked_df = processor.rerank_after_starring(df, starred_id=1)\n",
        "    >>> print(reranked_df['final_score'])\n",
        "    0    1.00  # HR Manager (exact match)\n",
        "    1    0.70  # HR Specialist (role mismatch but HR)\n",
        "    2    0.30  # Sales Manager (different domain)\n",
        "\n",
        "    Implementation:\n",
        "    1. Validates starred_id exists in dataframe\n",
        "    2. Calculates three similarity scores:\n",
        "       - Role type match (40%): Matches job level (manager, specialist etc)\n",
        "       - Experience match (30%): Matches seniority level\n",
        "       - Title similarity (30%): Overall keyword matching\n",
        "    3. Adds minor location bonus (5%) for same location\n",
        "    4. Combines scores for final ranking\n",
        "    5. Sorts by new scores and cleans temporary columns\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Get starred candidate\n",
        "            starred_id = int(starred_id)\n",
        "            if 'id' not in df.columns or starred_id not in df['id'].values:\n",
        "                return df\n",
        "            starred = df[df['id'] == starred_id].iloc[0]\n",
        "\n",
        "            def calculate_role_type_match(title: str, starred_title: str) -> float:\n",
        "                \"\"\"\n",
        "    Calculates similarity score based on role type matching.\n",
        "\n",
        "    Args:\n",
        "        title (str): Candidate's title\n",
        "        starred_title (str): Selected candidate's title\n",
        "\n",
        "    Returns:\n",
        "        float: 1.0 if same role type, 0.0 otherwise\n",
        "\n",
        "    Example:\n",
        "    >>> calculate_role_type_match(\"HR Manager\", \"Sales Manager\")\n",
        "    1.0  # Both are manager roles\n",
        "    >>> calculate_role_type_match(\"HR Manager\", \"HR Specialist\")\n",
        "    0.0\n",
        "    \"\"\"\n",
        "                role_types = ['specialist', 'manager', 'coordinator', 'generalist', 'director']\n",
        "                title_type = next((role for role in role_types if role in title.lower()), '')\n",
        "                starred_type = next((role for role in role_types if role in starred_title.lower()), '')\n",
        "                return 1.0 if title_type == starred_type else 0.0\n",
        "\n",
        "            def calculate_experience_match(title: str, starred_title: str) -> float:\n",
        "                \"\"\"\n",
        "    Calculates similarity score based on experience level matching.\n",
        "\n",
        "    Args:\n",
        "        title (str): Candidate's title\n",
        "        starred_title (str): Selected candidate's title\n",
        "\n",
        "    Returns:\n",
        "        float: 1.0 if same experience level, 0.0 otherwise\n",
        "\n",
        "    Example:\n",
        "    >>> calculate_experience_match(\"Senior HR Manager\", \"Senior Analyst\")\n",
        "    1.0  # Both senior roles\n",
        "    >>> calculate_experience_match(\"Junior HR\", \"Senior HR\")\n",
        "    0.0  # Different levels\n",
        "    \"\"\"\n",
        "\n",
        "                levels = ['senior', 'lead', 'principal', 'junior', 'associate', 'entry']\n",
        "                title_level = next((level for level in levels if level in title.lower()), '')\n",
        "                starred_level = next((level for level in levels if level in starred_title.lower()), '')\n",
        "                return 1.0 if title_level == starred_level else 0.0\n",
        "\n",
        "            def calculate_title_similarity(title: str, starred_title: str) -> float:\n",
        "                \"\"\"\n",
        "    Calculates overall title similarity using keyword matching.\n",
        "\n",
        "    Args:\n",
        "        title (str): Candidate's title\n",
        "        starred_title (str): Selected candidate's title\n",
        "\n",
        "    Returns:\n",
        "        float: Jaccard similarity score between title keywords (0.0-1.0)\n",
        "\n",
        "    Example:\n",
        "    >>> calculate_title_similarity(\"HR Manager Sales\", \"HR Director Marketing\")\n",
        "    0.25  # 1 common word (HR) out of 4 unique words\n",
        "    \"\"\"\n",
        "\n",
        "                title_keywords = set(title.lower().split())\n",
        "                starred_keywords = set(starred_title.lower().split())\n",
        "                common_keywords = title_keywords.intersection(starred_keywords)\n",
        "                return len(common_keywords) / max(len(title_keywords), len(starred_keywords))\n",
        "\n",
        "            # Calculate new scores without rank preservation\n",
        "            df['role_type_score'] = df['cleaned_title'].apply(\n",
        "                lambda x: calculate_role_type_match(x, starred['cleaned_title'])\n",
        "            ) * 0.40  # 40% weight\n",
        "\n",
        "            df['experience_score'] = df['cleaned_title'].apply(\n",
        "                lambda x: calculate_experience_match(x, starred['cleaned_title'])\n",
        "            ) * 0.30  # 30% weight\n",
        "\n",
        "            df['title_similarity_score'] = df['cleaned_title'].apply(\n",
        "                lambda x: calculate_title_similarity(x, starred['cleaned_title'])\n",
        "            ) * 0.30  # 30% weight\n",
        "\n",
        "            # Minor location boost (not part of main scoring)\n",
        "            df['location_bonus'] = df['cleaned_location'].apply(\n",
        "                lambda x: 0.05 if x == starred['cleaned_location'] else 0.0\n",
        "            )\n",
        "\n",
        "            # Calculate final reranked score without previous rank preservation\n",
        "            df['reranked_score'] = (\n",
        "                df['role_type_score'] +\n",
        "                df['experience_score'] +\n",
        "                df['title_similarity_score'] +\n",
        "                df['location_bonus']\n",
        "            )\n",
        "\n",
        "            # Update final scores and sort\n",
        "            df['final_score'] = df['reranked_score']\n",
        "            df = df.sort_values('final_score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "            # Clean up temporary columns\n",
        "            df = df.drop(['role_type_score', 'experience_score',\n",
        "                        'title_similarity_score', 'location_bonus',\n",
        "                        'reranked_score'], axis=1)\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Reranking error: {str(e)}\")\n",
        "            return df\n",
        "\n",
        "    def _update_role_categories(self, title: str) -> None:\n",
        "        \"\"\"\n",
        "    Updates metrics tracking for different HR role categories based on job title.\n",
        "    Increments counters for role categories and keyword matches in self.metrics.\n",
        "\n",
        "    Example:\n",
        "    >>> processor = HRTalentProcessor()\n",
        "    >>> processor._update_role_categories(\"Aspiring Human Resources Manager\")\n",
        "    # Updates metrics:\n",
        "    # self.metrics['role_categories']['aspiring_hr'] += 1\n",
        "    # self.metrics['keyword_matches']['aspiring'] += 1\n",
        "\n",
        "    Args:\n",
        "        title (str): Cleaned job title to categorize\n",
        "\n",
        "    Implementation:\n",
        "    1. If empty title, increment other_roles counter\n",
        "    2. Check for \"aspiring human resources\" -> aspiring_hr category\n",
        "    3. Check for \"seeking human resources\" -> seeking_hr category\n",
        "    4. Check for senior titles (chief, SVP, director) -> senior_hr\n",
        "    5. Check for mid-level titles (specialist, manager) -> mid_level_hr\n",
        "    6. Check for junior titles (coordinator) -> junior_hr\n",
        "    7. Check for non-HR prefix -> other_roles\n",
        "    8. Default to hr_adjacent if none of above\n",
        "    \"\"\"\n",
        "        if not title:\n",
        "            self.metrics['role_categories']['other_roles'] += 1\n",
        "            return\n",
        "\n",
        "        # Target Roles\n",
        "        if 'aspiring human resources' in title:\n",
        "            self.metrics['role_categories']['aspiring_hr'] += 1\n",
        "            self.metrics['keyword_matches']['aspiring'] += 1\n",
        "            return\n",
        "\n",
        "        if 'seeking human resources' in title:\n",
        "            self.metrics['role_categories']['seeking_hr'] += 1\n",
        "            self.metrics['keyword_matches']['seeking'] += 1\n",
        "            return\n",
        "\n",
        "        # Senior HR\n",
        "        if any(x in title for x in ['chief human resources', 'senior vice president', 'director']):\n",
        "            self.metrics['role_categories']['senior_hr'] += 1\n",
        "            self.metrics['keyword_matches']['other_hr'] += 1\n",
        "            return\n",
        "\n",
        "        # Mid-Level HR\n",
        "        if any(x in title for x in ['specialist', 'generalist', 'manager']):\n",
        "            self.metrics['role_categories']['mid_level_hr'] += 1\n",
        "            self.metrics['keyword_matches']['other_hr'] += 1\n",
        "            return\n",
        "\n",
        "        # Junior HR\n",
        "        if 'coordinator' in title:\n",
        "            self.metrics['role_categories']['junior_hr'] += 1\n",
        "            self.metrics['keyword_matches']['other_hr'] += 1\n",
        "            return\n",
        "\n",
        "        # HR Adjacent/Other\n",
        "        if title.startswith('NON-HR:'):\n",
        "            self.metrics['role_categories']['other_roles'] += 1\n",
        "        else:\n",
        "            self.metrics['role_categories']['hr_adjacent'] += 1\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function for HR talent ranking system.\n",
        "    Handles end-to-end process from data loading to results display.\n",
        "\n",
        "    Implementation steps:\n",
        "    1. Print system configuration and target profiles\n",
        "    2. Load candidate data from CSV file\n",
        "       - Handle file reading errors\n",
        "    3. Initialize HRTalentProcessor with:\n",
        "       - Multi-agent evaluation\n",
        "       - Genetic tie-breaking\n",
        "       - Clustering capability\n",
        "    4. Process candidate data:\n",
        "       - Clean and standardize fields\n",
        "       - Calculate initial rankings\n",
        "    5. Display initial ranking analysis\n",
        "    6. Demonstrate expert feedback:\n",
        "       - Select example candidate (7 ranked)\n",
        "       - Perform reranking based on starred candidate\n",
        "       - Display updated rankings\n",
        "    7. Return processor and results or (None, None) if errors\n",
        "\n",
        "     \"\"\"\n",
        "    try:\n",
        "        print(\"\\nHR TALENT RANKING SYSTEM\")\n",
        "        print(\"=\" * 80)\n",
        "        print(\"\\nSystem configuration focuses on project keywords:\")\n",
        "        print(\"- 'aspiring human resources': Primary target profile\")\n",
        "        print(\"- 'seeking human resources': Alternative target profile\")\n",
        "\n",
        "        print(\"\\nInitiating data loading process...\")\n",
        "        try:\n",
        "            # Load CSV file\n",
        "            df = pd.read_csv('/content/potential-talents - Aspiring human resources - seeking human resources (2).csv')\n",
        "            print(f\"Successfully loaded {len(df)} candidate profiles\")\n",
        "        except Exception as e:\n",
        "            print(f\"Data loading error: {str(e)}\")\n",
        "            return None, None\n",
        "\n",
        "        print(\"\\nConfiguring HR talent processor...\")\n",
        "        processor = HRTalentProcessor()\n",
        "        print(\"Processor initialized with:\")\n",
        "        print(\"- Multi-agent evaluation system\")\n",
        "        print(\"- Genetic tie-breaking algorithm\")\n",
        "        print(\"- Clustering capability\")\n",
        "\n",
        "        print(\"\\nExecuting initial candidate evaluation...\")\n",
        "        results = processor.process_data(df)\n",
        "\n",
        "        if results.empty:\n",
        "            print(\"\\nProcessing Error: No valid candidates identified\")\n",
        "            print(\"Please verify data format and content\")\n",
        "            return None, None\n",
        "\n",
        "        print(\"\\nINITIAL RANKING ANALYSIS\")\n",
        "        processor.display_results(results)\n",
        "\n",
        "        # Display project challenges analysis\n",
        "        processor.display_project_challenges(results)\n",
        "\n",
        "        print(\"\\nDEMONSTRATING EXPERT FEEDBACK MECHANISM\")\n",
        "        if len(results) >= 7:\n",
        "            # Take 7th candidate as example\n",
        "            starred_id = results.iloc[6]['id']\n",
        "            starred = results.iloc[6]\n",
        "\n",
        "            print(f\"\\nSimulating expert feedback by starring candidate:\")\n",
        "            print(f\"ID: {starred['id']}\")\n",
        "            print(f\"Title: {starred['job_title']}\")\n",
        "\n",
        "            # Perform reranking\n",
        "            updated_results = processor.rerank_after_starring(results, starred_id)\n",
        "\n",
        "            print(\"\\nUPDATED RANKING ANALYSIS (Post-Feedback)\")\n",
        "            processor.display_results(updated_results)\n",
        "\n",
        "        return processor, results\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"\\nCritical error in main execution: {str(e)}\")\n",
        "        print(f\"\\nSystem encountered an unexpected error: {str(e)}\")\n",
        "        print(\"Please check the log for detailed error information\")\n",
        "        return None, None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    processor, results = main()\n",
        "\n",
        "    if processor is None or results is None:\n",
        "        print(\"\\nSystem execution failed. Please check error messages above.\")\n",
        "    else:\n",
        "        print(\"\\nSystem execution completed successfully.\")\n",
        "        print(f\"Processed {len(results)} candidates\")\n",
        "        print(\"Use processor.display_results(results) for detailed analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khfz66lQpURM",
        "outputId": "a138f828-e5ee-4be8-b72b-84ec757fa059"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: Levenshtein==0.26.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.26.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.26.1->python-Levenshtein) (3.12.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\n",
            "HR TALENT RANKING SYSTEM\n",
            "================================================================================\n",
            "\n",
            "System configuration focuses on project keywords:\n",
            "- 'aspiring human resources': Primary target profile\n",
            "- 'seeking human resources': Alternative target profile\n",
            "\n",
            "Initiating data loading process...\n",
            "Successfully loaded 104 candidate profiles\n",
            "\n",
            "Configuring HR talent processor...\n",
            "Processor initialized with:\n",
            "- Multi-agent evaluation system\n",
            "- Genetic tie-breaking algorithm\n",
            "- Clustering capability\n",
            "\n",
            "Executing initial candidate evaluation...\n",
            "\n",
            "INITIAL RANKING ANALYSIS\n",
            "\n",
            "# HR TALENT RANKING ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "## CANDIDATE DISTRIBUTION\n",
            "\n",
            "| Category | Count | Percentage |\n",
            "|----------|--------|------------|\n",
            "| Target Roles (≥0.90) | 49 | 47.115 |\n",
            "| Senior HR (0.40-0.89) | 27 | 25.962 |\n",
            "| Other Roles (<0.40) | 28 | 26.923 |\n",
            "\n",
            "## SCORE GUIDE\n",
            "\n",
            "| Priority | Range | Category |\n",
            "|----------|--------|----------|\n",
            "| High | 0.90 - 1.00 | Primary Target |\n",
            "| High | 0.40 - 0.89 | Senior HR |\n",
            "| Low | 0.05 - 0.39 | Other/Non-HR |\n",
            "\n",
            "## TOP 10 PRIMARY TARGET CANDIDATES (Score ≥ 0.90)\n",
            "\n",
            "| ID | Job Title | Cleaned Title | Location | Connections | Score |\n",
            "|----|-----------|---------------|----------|-------------|-------|\n",
            "| 1 | 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional | aspiring human resources professional | texas | 85 | 1.000 |\n",
            "| 3 | Aspiring Human Resources Professional | aspiring human resources professional | north carolina | 44 | 1.000 |\n",
            "| 6 | Aspiring Human Resources Specialist | aspiring human resources specialist | new york | 1 | 1.000 |\n",
            "| 7 | Student at Humber College and Aspiring Human Resources Generalist | aspiring human resources generalist | canada | 61 | 1.000 |\n",
            "| 9 | Student at Humber College and Aspiring Human Resources Generalist | aspiring human resources generalist | canada | 61 | 1.000 |\n",
            "| 10 | Seeking Human Resources HRIS and Generalist Positions | seeking human resources hris position |  philadelphia  | 500 | 1.000 |\n",
            "| 14 | 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional | aspiring human resources professional | texas | 85 | 1.000 |\n",
            "| 15 | 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional | aspiring human resources professional | texas | 85 | 1.000 |\n",
            "| 17 | Aspiring Human Resources Professional | aspiring human resources professional | north carolina | 44 | 1.000 |\n",
            "| 19 | 2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional | aspiring human resources professional | texas | 85 | 1.000 |\n",
            "\n",
            "## TOP 10 SENIOR HR PROFESSIONALS (Score 0.40-0.89)\n",
            "\n",
            "| ID | Job Title | Cleaned Title | Location | Connections | Score |\n",
            "|----|-----------|---------------|----------|-------------|-------|\n",
            "| 8 | HR Senior Specialist | senior human resources specialist | california | 500 | 0.853 |\n",
            "| 26 | HR Senior Specialist | senior human resources specialist | california | 500 | 0.853 |\n",
            "| 38 | HR Senior Specialist | senior human resources specialist | california | 500 | 0.853 |\n",
            "| 51 | HR Senior Specialist | senior human resources specialist | california | 500 | 0.853 |\n",
            "| 61 | HR Senior Specialist | senior human resources specialist | california | 500 | 0.853 |\n",
            "| 68 | Human Resources Specialist at Luxottica | human resources specialist | new york | 500 | 0.678 |\n",
            "| 81 | Senior Human Resources Business Partner at Heil Environmental | senior human resources specialist | tennessee | 455 | 0.853 |\n",
            "| 83 | HR Manager at Endemol Shine North America | human resources manager | california | 268 | 0.736 |\n",
            "\n",
            "## TOP 10 OTHER ROLES (Score < 0.40)\n",
            "\n",
            "| ID | Job Title | Cleaned Title | Location | Connections | Score |\n",
            "|----|-----------|---------------|----------|-------------|-------|\n",
            "| 2 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.054 |\n",
            "| 5 | Advisory Board Member at Celal Bayar University | NON-HR: Other | turkey | 500 | 0.054 |\n",
            "| 11 | Student at Chapman University | NON-HR: Student | california | 2 | 0.054 |\n",
            "| 16 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.054 |\n",
            "| 20 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.054 |\n",
            "| 23 | Advisory Board Member at Celal Bayar University | NON-HR: Other | turkey | 500 | 0.054 |\n",
            "| 32 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.054 |\n",
            "| 35 | Advisory Board Member at Celal Bayar University | NON-HR: Other | turkey | 500 | 0.054 |\n",
            "| 41 | Student at Chapman University | NON-HR: Student | california | 2 | 0.054 |\n",
            "| 45 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.054 |\n",
            "\n",
            " ANALYSIS OF PROJECT CHALLENGES\n",
            "====================================================================================================\n",
            "\n",
            "1. Algorithm Performance & Effectiveness\n",
            "--------------------------------------------------\n",
            "Our scoring system combines multiple factors with weighted importance:\n",
            "• Job Title Analysis (90% of total score)\n",
            "  - Identifies aspiring and seeking HR professionals\n",
            "  - Evaluates current HR role levels\n",
            "• Location Impact (5% of total score)\n",
            "  - Considers tech hubs and major markets\n",
            "• Professional Network (5% of total score)\n",
            "  - Measures industry connections\n",
            "\n",
            "2. Candidate Pool Analysis\n",
            "--------------------------------------------------\n",
            "From 104 total candidates:\n",
            "• Primary targets: 49 (47.1%)\n",
            "• Qualified HR professionals: 27 (26.0%)\n",
            "• Non-HR profiles: 28 (26.9%)\n",
            "\n",
            "3. Quality Control & Cutoff Analysis\n",
            "--------------------------------------------------\n",
            "Dynamic scoring thresholds:\n",
            "• Target threshold: 0.90\n",
            "• High-potential candidates: 49 profiles\n",
            "• Qualified HR threshold: 0.40\n",
            "\n",
            "4. Bias Prevention & Fair Evaluation\n",
            "--------------------------------------------------\n",
            "Multiple measures ensure unbiased assessment:\n",
            "• Role-based scoring prioritizes relevant experience\n",
            "• Location consideration limited to 5% impact\n",
            "• Network size normalized to prevent seniority bias\n",
            "• Cluster analysis promotes diverse candidate pool\n",
            "\n",
            "DEMONSTRATING EXPERT FEEDBACK MECHANISM\n",
            "\n",
            "Simulating expert feedback by starring candidate:\n",
            "ID: 7\n",
            "Title: Student at Humber College and Aspiring Human Resources Generalist\n",
            "\n",
            "UPDATED RANKING ANALYSIS (Post-Feedback)\n",
            "\n",
            "# HR TALENT RANKING ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "## CANDIDATE DISTRIBUTION\n",
            "\n",
            "| Category | Count | Percentage |\n",
            "|----------|--------|------------|\n",
            "| Target Roles (≥0.90) | 10 | 9.615 |\n",
            "| Senior HR (0.40-0.89) | 54 | 51.923 |\n",
            "| Other Roles (<0.40) | 40 | 38.462 |\n",
            "\n",
            "## SCORE GUIDE\n",
            "\n",
            "| Priority | Range | Category |\n",
            "|----------|--------|----------|\n",
            "| High | 0.90 - 1.00 | Primary Target |\n",
            "| High | 0.40 - 0.89 | Senior HR |\n",
            "| Low | 0.05 - 0.39 | Other/Non-HR |\n",
            "\n",
            "## TOP 10 PRIMARY TARGET CANDIDATES (Score ≥ 0.90)\n",
            "\n",
            "| ID | Job Title | Cleaned Title | Location | Connections | Score |\n",
            "|----|-----------|---------------|----------|-------------|-------|\n",
            "| 25 | Student at Humber College and Aspiring Human Resources Generalist | aspiring human resources generalist | canada | 61 | 1.050 |\n",
            "| 7 | Student at Humber College and Aspiring Human Resources Generalist | aspiring human resources generalist | canada | 61 | 1.050 |\n",
            "| 9 | Student at Humber College and Aspiring Human Resources Generalist | aspiring human resources generalist | canada | 61 | 1.050 |\n",
            "| 52 | Student at Humber College and Aspiring Human Resources Generalist | aspiring human resources generalist | canada | 61 | 1.050 |\n",
            "| 50 | Student at Humber College and Aspiring Human Resources Generalist | aspiring human resources generalist | canada | 61 | 1.050 |\n",
            "| 37 | Student at Humber College and Aspiring Human Resources Generalist | aspiring human resources generalist | canada | 61 | 1.050 |\n",
            "| 39 | Student at Humber College and Aspiring Human Resources Generalist | aspiring human resources generalist | canada | 61 | 1.050 |\n",
            "\n",
            "## TOP 10 SENIOR HR PROFESSIONALS (Score 0.40-0.89)\n",
            "\n",
            "| ID | Job Title | Cleaned Title | Location | Connections | Score |\n",
            "|----|-----------|---------------|----------|-------------|-------|\n",
            "| 83 | HR Manager at Endemol Shine North America | human resources manager | california | 268 | 0.450 |\n",
            "| 89 | Director Human Resources  at EY | director human resources |  atlanta  | 349 | 0.450 |\n",
            "| 55 | SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR | chief human resources officer | texas | 500 | 0.450 |\n",
            "| 68 | Human Resources Specialist at Luxottica | human resources specialist | new york | 500 | 0.450 |\n",
            "| 12 | SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR | chief human resources officer | texas | 500 | 0.450 |\n",
            "| 69 | Director of Human Resources North America, Groupe Beneteau | director human resources | michigan | 500 | 0.450 |\n",
            "| 42 | SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR | chief human resources officer | texas | 500 | 0.450 |\n",
            "| 64 | SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR | chief human resources officer | texas | 500 | 0.450 |\n",
            "\n",
            "## TOP 10 OTHER ROLES (Score < 0.40)\n",
            "\n",
            "| ID | Job Title | Cleaned Title | Location | Connections | Score |\n",
            "|----|-----------|---------------|----------|-------------|-------|\n",
            "| 32 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.350 |\n",
            "| 16 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.350 |\n",
            "| 20 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.350 |\n",
            "| 2 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.350 |\n",
            "| 45 | Native English Teacher at EPIK (English Program in Korea) | NON-HR: Education | canada | 500 | 0.350 |\n",
            "| 63 | Student at Chapman University | NON-HR: Student | california | 2 | 0.300 |\n",
            "| 11 | Student at Chapman University | NON-HR: Student | california | 2 | 0.300 |\n",
            "| 90 | Undergraduate Research Assistant at Styczynski Lab | NON-HR: Research |  atlanta  | 155 | 0.300 |\n",
            "| 91 | Lead Official at Western Illinois University | NON-HR: Other | illinois | 39 | 0.300 |\n",
            "| 92 | Seeking employment opportunities within Customer Service or Patient Care | NON-HR: Other | california | 64 | 0.300 |\n",
            "\n",
            "System execution completed successfully.\n",
            "Processed 104 candidates\n",
            "Use processor.display_results(results) for detailed analysis\n"
          ]
        }
      ]
    }
  ]
}